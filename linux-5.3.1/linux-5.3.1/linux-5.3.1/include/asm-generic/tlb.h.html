<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>tlb.h source code [linux-5.3.1/include/asm-generic/tlb.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="mmu_gather,mmu_gather_batch "/>
<link rel="stylesheet" href="../../../../data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="../../../../data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="../../../../data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../../../../data/jquery/jquery-ui.min.js"></script>
<script>var file = 'linux-5.3.1/include/asm-generic/tlb.h'; var root_path = '../../..'; var data_path = '../../../../data'; var ecma_script_api_version = 2;</script>
<script src='../../../../data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../..'>linux-5.3.1</a>/<a href='..'>include</a>/<a href='./'>asm-generic</a>/<a href='tlb.h.html'>tlb.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* SPDX-License-Identifier: GPL-2.0-or-later */</i></td></tr>
<tr><th id="2">2</th><td><i>/* include/asm-generic/tlb.h</i></td></tr>
<tr><th id="3">3</th><td><i> *</i></td></tr>
<tr><th id="4">4</th><td><i> *	Generic TLB shootdown code</i></td></tr>
<tr><th id="5">5</th><td><i> *</i></td></tr>
<tr><th id="6">6</th><td><i> * Copyright 2001 Red Hat, Inc.</i></td></tr>
<tr><th id="7">7</th><td><i> * Based on code from mm/memory.c Copyright Linus Torvalds and others.</i></td></tr>
<tr><th id="8">8</th><td><i> *</i></td></tr>
<tr><th id="9">9</th><td><i> * Copyright 2011 Red Hat, Inc., Peter Zijlstra</i></td></tr>
<tr><th id="10">10</th><td><i> */</i></td></tr>
<tr><th id="11">11</th><td><u>#<span data-ppcond="11">ifndef</span> <span class="macro" data-ref="_M/_ASM_GENERIC__TLB_H">_ASM_GENERIC__TLB_H</span></u></td></tr>
<tr><th id="12">12</th><td><u>#define <dfn class="macro" id="_M/_ASM_GENERIC__TLB_H" data-ref="_M/_ASM_GENERIC__TLB_H">_ASM_GENERIC__TLB_H</dfn></u></td></tr>
<tr><th id="13">13</th><td></td></tr>
<tr><th id="14">14</th><td><u>#include <a href="../linux/mmu_notifier.h.html">&lt;linux/mmu_notifier.h&gt;</a></u></td></tr>
<tr><th id="15">15</th><td><u>#include <a href="../linux/swap.h.html">&lt;linux/swap.h&gt;</a></u></td></tr>
<tr><th id="16">16</th><td><u>#include <a href="../../arch/x86/include/asm/pgalloc.h.html">&lt;asm/pgalloc.h&gt;</a></u></td></tr>
<tr><th id="17">17</th><td><u>#include <a href="../../arch/x86/include/asm/tlbflush.h.html">&lt;asm/tlbflush.h&gt;</a></u></td></tr>
<tr><th id="18">18</th><td><u>#include <a href="../../arch/x86/include/asm/cacheflush.h.html">&lt;asm/cacheflush.h&gt;</a></u></td></tr>
<tr><th id="19">19</th><td></td></tr>
<tr><th id="20">20</th><td><i>/*</i></td></tr>
<tr><th id="21">21</th><td><i> * Blindly accessing user memory from NMI context can be dangerous</i></td></tr>
<tr><th id="22">22</th><td><i> * if we're in the middle of switching the current user task or switching</i></td></tr>
<tr><th id="23">23</th><td><i> * the loaded mm.</i></td></tr>
<tr><th id="24">24</th><td><i> */</i></td></tr>
<tr><th id="25">25</th><td><u>#<span data-ppcond="25">ifndef</span> <a class="macro" href="../../arch/x86/include/asm/tlbflush.h.html#277" data-ref="_M/nmi_uaccess_okay">nmi_uaccess_okay</a></u></td></tr>
<tr><th id="26">26</th><td><u># define nmi_uaccess_okay() true</u></td></tr>
<tr><th id="27">27</th><td><u>#<span data-ppcond="25">endif</span></u></td></tr>
<tr><th id="28">28</th><td></td></tr>
<tr><th id="29">29</th><td><u>#<span data-ppcond="29">ifdef</span> <a class="macro" href="../generated/autoconf.h.html#1383" data-ref="_M/CONFIG_MMU">CONFIG_MMU</a></u></td></tr>
<tr><th id="30">30</th><td></td></tr>
<tr><th id="31">31</th><td><i>/*</i></td></tr>
<tr><th id="32">32</th><td><i> * Generic MMU-gather implementation.</i></td></tr>
<tr><th id="33">33</th><td><i> *</i></td></tr>
<tr><th id="34">34</th><td><i> * The mmu_gather data structure is used by the mm code to implement the</i></td></tr>
<tr><th id="35">35</th><td><i> * correct and efficient ordering of freeing pages and TLB invalidations.</i></td></tr>
<tr><th id="36">36</th><td><i> *</i></td></tr>
<tr><th id="37">37</th><td><i> * This correct ordering is:</i></td></tr>
<tr><th id="38">38</th><td><i> *</i></td></tr>
<tr><th id="39">39</th><td><i> *  1) unhook page</i></td></tr>
<tr><th id="40">40</th><td><i> *  2) TLB invalidate page</i></td></tr>
<tr><th id="41">41</th><td><i> *  3) free page</i></td></tr>
<tr><th id="42">42</th><td><i> *</i></td></tr>
<tr><th id="43">43</th><td><i> * That is, we must never free a page before we have ensured there are no live</i></td></tr>
<tr><th id="44">44</th><td><i> * translations left to it. Otherwise it might be possible to observe (or</i></td></tr>
<tr><th id="45">45</th><td><i> * worse, change) the page content after it has been reused.</i></td></tr>
<tr><th id="46">46</th><td><i> *</i></td></tr>
<tr><th id="47">47</th><td><i> * The mmu_gather API consists of:</i></td></tr>
<tr><th id="48">48</th><td><i> *</i></td></tr>
<tr><th id="49">49</th><td><i> *  - tlb_gather_mmu() / tlb_finish_mmu(); start and finish a mmu_gather</i></td></tr>
<tr><th id="50">50</th><td><i> *</i></td></tr>
<tr><th id="51">51</th><td><i> *    Finish in particular will issue a (final) TLB invalidate and free</i></td></tr>
<tr><th id="52">52</th><td><i> *    all (remaining) queued pages.</i></td></tr>
<tr><th id="53">53</th><td><i> *</i></td></tr>
<tr><th id="54">54</th><td><i> *  - tlb_start_vma() / tlb_end_vma(); marks the start / end of a VMA</i></td></tr>
<tr><th id="55">55</th><td><i> *</i></td></tr>
<tr><th id="56">56</th><td><i> *    Defaults to flushing at tlb_end_vma() to reset the range; helps when</i></td></tr>
<tr><th id="57">57</th><td><i> *    there's large holes between the VMAs.</i></td></tr>
<tr><th id="58">58</th><td><i> *</i></td></tr>
<tr><th id="59">59</th><td><i> *  - tlb_remove_page() / __tlb_remove_page()</i></td></tr>
<tr><th id="60">60</th><td><i> *  - tlb_remove_page_size() / __tlb_remove_page_size()</i></td></tr>
<tr><th id="61">61</th><td><i> *</i></td></tr>
<tr><th id="62">62</th><td><i> *    __tlb_remove_page_size() is the basic primitive that queues a page for</i></td></tr>
<tr><th id="63">63</th><td><i> *    freeing. __tlb_remove_page() assumes PAGE_SIZE. Both will return a</i></td></tr>
<tr><th id="64">64</th><td><i> *    boolean indicating if the queue is (now) full and a call to</i></td></tr>
<tr><th id="65">65</th><td><i> *    tlb_flush_mmu() is required.</i></td></tr>
<tr><th id="66">66</th><td><i> *</i></td></tr>
<tr><th id="67">67</th><td><i> *    tlb_remove_page() and tlb_remove_page_size() imply the call to</i></td></tr>
<tr><th id="68">68</th><td><i> *    tlb_flush_mmu() when required and has no return value.</i></td></tr>
<tr><th id="69">69</th><td><i> *</i></td></tr>
<tr><th id="70">70</th><td><i> *  - tlb_change_page_size()</i></td></tr>
<tr><th id="71">71</th><td><i> *</i></td></tr>
<tr><th id="72">72</th><td><i> *    call before __tlb_remove_page*() to set the current page-size; implies a</i></td></tr>
<tr><th id="73">73</th><td><i> *    possible tlb_flush_mmu() call.</i></td></tr>
<tr><th id="74">74</th><td><i> *</i></td></tr>
<tr><th id="75">75</th><td><i> *  - tlb_flush_mmu() / tlb_flush_mmu_tlbonly()</i></td></tr>
<tr><th id="76">76</th><td><i> *</i></td></tr>
<tr><th id="77">77</th><td><i> *    tlb_flush_mmu_tlbonly() - does the TLB invalidate (and resets</i></td></tr>
<tr><th id="78">78</th><td><i> *                              related state, like the range)</i></td></tr>
<tr><th id="79">79</th><td><i> *</i></td></tr>
<tr><th id="80">80</th><td><i> *    tlb_flush_mmu() - in addition to the above TLB invalidate, also frees</i></td></tr>
<tr><th id="81">81</th><td><i> *			whatever pages are still batched.</i></td></tr>
<tr><th id="82">82</th><td><i> *</i></td></tr>
<tr><th id="83">83</th><td><i> *  - mmu_gather::fullmm</i></td></tr>
<tr><th id="84">84</th><td><i> *</i></td></tr>
<tr><th id="85">85</th><td><i> *    A flag set by tlb_gather_mmu() to indicate we're going to free</i></td></tr>
<tr><th id="86">86</th><td><i> *    the entire mm; this allows a number of optimizations.</i></td></tr>
<tr><th id="87">87</th><td><i> *</i></td></tr>
<tr><th id="88">88</th><td><i> *    - We can ignore tlb_{start,end}_vma(); because we don't</i></td></tr>
<tr><th id="89">89</th><td><i> *      care about ranges. Everything will be shot down.</i></td></tr>
<tr><th id="90">90</th><td><i> *</i></td></tr>
<tr><th id="91">91</th><td><i> *    - (RISC) architectures that use ASIDs can cycle to a new ASID</i></td></tr>
<tr><th id="92">92</th><td><i> *      and delay the invalidation until ASID space runs out.</i></td></tr>
<tr><th id="93">93</th><td><i> *</i></td></tr>
<tr><th id="94">94</th><td><i> *  - mmu_gather::need_flush_all</i></td></tr>
<tr><th id="95">95</th><td><i> *</i></td></tr>
<tr><th id="96">96</th><td><i> *    A flag that can be set by the arch code if it wants to force</i></td></tr>
<tr><th id="97">97</th><td><i> *    flush the entire TLB irrespective of the range. For instance</i></td></tr>
<tr><th id="98">98</th><td><i> *    x86-PAE needs this when changing top-level entries.</i></td></tr>
<tr><th id="99">99</th><td><i> *</i></td></tr>
<tr><th id="100">100</th><td><i> * And allows the architecture to provide and implement tlb_flush():</i></td></tr>
<tr><th id="101">101</th><td><i> *</i></td></tr>
<tr><th id="102">102</th><td><i> * tlb_flush() may, in addition to the above mentioned mmu_gather fields, make</i></td></tr>
<tr><th id="103">103</th><td><i> * use of:</i></td></tr>
<tr><th id="104">104</th><td><i> *</i></td></tr>
<tr><th id="105">105</th><td><i> *  - mmu_gather::start / mmu_gather::end</i></td></tr>
<tr><th id="106">106</th><td><i> *</i></td></tr>
<tr><th id="107">107</th><td><i> *    which provides the range that needs to be flushed to cover the pages to</i></td></tr>
<tr><th id="108">108</th><td><i> *    be freed.</i></td></tr>
<tr><th id="109">109</th><td><i> *</i></td></tr>
<tr><th id="110">110</th><td><i> *  - mmu_gather::freed_tables</i></td></tr>
<tr><th id="111">111</th><td><i> *</i></td></tr>
<tr><th id="112">112</th><td><i> *    set when we freed page table pages</i></td></tr>
<tr><th id="113">113</th><td><i> *</i></td></tr>
<tr><th id="114">114</th><td><i> *  - tlb_get_unmap_shift() / tlb_get_unmap_size()</i></td></tr>
<tr><th id="115">115</th><td><i> *</i></td></tr>
<tr><th id="116">116</th><td><i> *    returns the smallest TLB entry size unmapped in this range.</i></td></tr>
<tr><th id="117">117</th><td><i> *</i></td></tr>
<tr><th id="118">118</th><td><i> * If an architecture does not provide tlb_flush() a default implementation</i></td></tr>
<tr><th id="119">119</th><td><i> * based on flush_tlb_range() will be used, unless MMU_GATHER_NO_RANGE is</i></td></tr>
<tr><th id="120">120</th><td><i> * specified, in which case we'll default to flush_tlb_mm().</i></td></tr>
<tr><th id="121">121</th><td><i> *</i></td></tr>
<tr><th id="122">122</th><td><i> * Additionally there are a few opt-in features:</i></td></tr>
<tr><th id="123">123</th><td><i> *</i></td></tr>
<tr><th id="124">124</th><td><i> *  HAVE_MMU_GATHER_PAGE_SIZE</i></td></tr>
<tr><th id="125">125</th><td><i> *</i></td></tr>
<tr><th id="126">126</th><td><i> *  This ensures we call tlb_flush() every time tlb_change_page_size() actually</i></td></tr>
<tr><th id="127">127</th><td><i> *  changes the size and provides mmu_gather::page_size to tlb_flush().</i></td></tr>
<tr><th id="128">128</th><td><i> *</i></td></tr>
<tr><th id="129">129</th><td><i> *  HAVE_RCU_TABLE_FREE</i></td></tr>
<tr><th id="130">130</th><td><i> *</i></td></tr>
<tr><th id="131">131</th><td><i> *  This provides tlb_remove_table(), to be used instead of tlb_remove_page()</i></td></tr>
<tr><th id="132">132</th><td><i> *  for page directores (__p*_free_tlb()). This provides separate freeing of</i></td></tr>
<tr><th id="133">133</th><td><i> *  the page-table pages themselves in a semi-RCU fashion (see comment below).</i></td></tr>
<tr><th id="134">134</th><td><i> *  Useful if your architecture doesn't use IPIs for remote TLB invalidates</i></td></tr>
<tr><th id="135">135</th><td><i> *  and therefore doesn't naturally serialize with software page-table walkers.</i></td></tr>
<tr><th id="136">136</th><td><i> *</i></td></tr>
<tr><th id="137">137</th><td><i> *  When used, an architecture is expected to provide __tlb_remove_table()</i></td></tr>
<tr><th id="138">138</th><td><i> *  which does the actual freeing of these pages.</i></td></tr>
<tr><th id="139">139</th><td><i> *</i></td></tr>
<tr><th id="140">140</th><td><i> *  HAVE_RCU_TABLE_NO_INVALIDATE</i></td></tr>
<tr><th id="141">141</th><td><i> *</i></td></tr>
<tr><th id="142">142</th><td><i> *  This makes HAVE_RCU_TABLE_FREE avoid calling tlb_flush_mmu_tlbonly() before</i></td></tr>
<tr><th id="143">143</th><td><i> *  freeing the page-table pages. This can be avoided if you use</i></td></tr>
<tr><th id="144">144</th><td><i> *  HAVE_RCU_TABLE_FREE and your architecture does _NOT_ use the Linux</i></td></tr>
<tr><th id="145">145</th><td><i> *  page-tables natively.</i></td></tr>
<tr><th id="146">146</th><td><i> *</i></td></tr>
<tr><th id="147">147</th><td><i> *  MMU_GATHER_NO_RANGE</i></td></tr>
<tr><th id="148">148</th><td><i> *</i></td></tr>
<tr><th id="149">149</th><td><i> *  Use this if your architecture lacks an efficient flush_tlb_range().</i></td></tr>
<tr><th id="150">150</th><td><i> */</i></td></tr>
<tr><th id="151">151</th><td></td></tr>
<tr><th id="152">152</th><td><u>#<span data-ppcond="152">ifdef</span> <span class="macro" data-ref="_M/CONFIG_HAVE_RCU_TABLE_FREE">CONFIG_HAVE_RCU_TABLE_FREE</span></u></td></tr>
<tr><th id="153">153</th><td><i>/*</i></td></tr>
<tr><th id="154">154</th><td><i> * Semi RCU freeing of the page directories.</i></td></tr>
<tr><th id="155">155</th><td><i> *</i></td></tr>
<tr><th id="156">156</th><td><i> * This is needed by some architectures to implement software pagetable walkers.</i></td></tr>
<tr><th id="157">157</th><td><i> *</i></td></tr>
<tr><th id="158">158</th><td><i> * gup_fast() and other software pagetable walkers do a lockless page-table</i></td></tr>
<tr><th id="159">159</th><td><i> * walk and therefore needs some synchronization with the freeing of the page</i></td></tr>
<tr><th id="160">160</th><td><i> * directories. The chosen means to accomplish that is by disabling IRQs over</i></td></tr>
<tr><th id="161">161</th><td><i> * the walk.</i></td></tr>
<tr><th id="162">162</th><td><i> *</i></td></tr>
<tr><th id="163">163</th><td><i> * Architectures that use IPIs to flush TLBs will then automagically DTRT,</i></td></tr>
<tr><th id="164">164</th><td><i> * since we unlink the page, flush TLBs, free the page. Since the disabling of</i></td></tr>
<tr><th id="165">165</th><td><i> * IRQs delays the completion of the TLB flush we can never observe an already</i></td></tr>
<tr><th id="166">166</th><td><i> * freed page.</i></td></tr>
<tr><th id="167">167</th><td><i> *</i></td></tr>
<tr><th id="168">168</th><td><i> * Architectures that do not have this (PPC) need to delay the freeing by some</i></td></tr>
<tr><th id="169">169</th><td><i> * other means, this is that means.</i></td></tr>
<tr><th id="170">170</th><td><i> *</i></td></tr>
<tr><th id="171">171</th><td><i> * What we do is batch the freed directory pages (tables) and RCU free them.</i></td></tr>
<tr><th id="172">172</th><td><i> * We use the sched RCU variant, as that guarantees that IRQ/preempt disabling</i></td></tr>
<tr><th id="173">173</th><td><i> * holds off grace periods.</i></td></tr>
<tr><th id="174">174</th><td><i> *</i></td></tr>
<tr><th id="175">175</th><td><i> * However, in order to batch these pages we need to allocate storage, this</i></td></tr>
<tr><th id="176">176</th><td><i> * allocation is deep inside the MM code and can thus easily fail on memory</i></td></tr>
<tr><th id="177">177</th><td><i> * pressure. To guarantee progress we fall back to single table freeing, see</i></td></tr>
<tr><th id="178">178</th><td><i> * the implementation of tlb_remove_table_one().</i></td></tr>
<tr><th id="179">179</th><td><i> *</i></td></tr>
<tr><th id="180">180</th><td><i> */</i></td></tr>
<tr><th id="181">181</th><td><b>struct</b> mmu_table_batch {</td></tr>
<tr><th id="182">182</th><td>	<b>struct</b> rcu_head		rcu;</td></tr>
<tr><th id="183">183</th><td>	<em>unsigned</em> <em>int</em>		nr;</td></tr>
<tr><th id="184">184</th><td>	<em>void</em>			*tables[<var>0</var>];</td></tr>
<tr><th id="185">185</th><td>};</td></tr>
<tr><th id="186">186</th><td></td></tr>
<tr><th id="187">187</th><td><u>#define MAX_TABLE_BATCH		\</u></td></tr>
<tr><th id="188">188</th><td><u>	((PAGE_SIZE - sizeof(struct mmu_table_batch)) / sizeof(void *))</u></td></tr>
<tr><th id="189">189</th><td></td></tr>
<tr><th id="190">190</th><td><b>extern</b> <em>void</em> tlb_remove_table(<b>struct</b> mmu_gather *tlb, <em>void</em> *table);</td></tr>
<tr><th id="191">191</th><td></td></tr>
<tr><th id="192">192</th><td><u>#<span data-ppcond="152">endif</span></u></td></tr>
<tr><th id="193">193</th><td></td></tr>
<tr><th id="194">194</th><td><u>#<span data-ppcond="194">ifndef</span> <span class="macro" data-ref="_M/CONFIG_HAVE_MMU_GATHER_NO_GATHER">CONFIG_HAVE_MMU_GATHER_NO_GATHER</span></u></td></tr>
<tr><th id="195">195</th><td><i>/*</i></td></tr>
<tr><th id="196">196</th><td><i> * If we can't allocate a page to make a big batch of page pointers</i></td></tr>
<tr><th id="197">197</th><td><i> * to work on, then just handle a few from the on-stack structure.</i></td></tr>
<tr><th id="198">198</th><td><i> */</i></td></tr>
<tr><th id="199">199</th><td><u>#define <dfn class="macro" id="_M/MMU_GATHER_BUNDLE" data-ref="_M/MMU_GATHER_BUNDLE">MMU_GATHER_BUNDLE</dfn>	8</u></td></tr>
<tr><th id="200">200</th><td></td></tr>
<tr><th id="201">201</th><td><b>struct</b> <dfn class="type def" id="mmu_gather_batch" title='mmu_gather_batch' data-ref="mmu_gather_batch" data-ref-filename="mmu_gather_batch">mmu_gather_batch</dfn> {</td></tr>
<tr><th id="202">202</th><td>	<b>struct</b> <a class="type" href="#mmu_gather_batch" title='mmu_gather_batch' data-ref="mmu_gather_batch" data-ref-filename="mmu_gather_batch">mmu_gather_batch</a>	*<dfn class="decl field" id="mmu_gather_batch::next" title='mmu_gather_batch::next' data-ref="mmu_gather_batch::next" data-ref-filename="mmu_gather_batch..next">next</dfn>;</td></tr>
<tr><th id="203">203</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather_batch::nr" title='mmu_gather_batch::nr' data-ref="mmu_gather_batch::nr" data-ref-filename="mmu_gather_batch..nr">nr</dfn>;</td></tr>
<tr><th id="204">204</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather_batch::max" title='mmu_gather_batch::max' data-ref="mmu_gather_batch::max" data-ref-filename="mmu_gather_batch..max">max</dfn>;</td></tr>
<tr><th id="205">205</th><td>	<b>struct</b> <a class="type" href="../linux/mm_types.h.html#page" title='page' data-ref="page" data-ref-filename="page">page</a>		*<dfn class="decl field" id="mmu_gather_batch::pages" title='mmu_gather_batch::pages' data-ref="mmu_gather_batch::pages" data-ref-filename="mmu_gather_batch..pages">pages</dfn>[<var>0</var>];</td></tr>
<tr><th id="206">206</th><td>};</td></tr>
<tr><th id="207">207</th><td></td></tr>
<tr><th id="208">208</th><td><u>#define <dfn class="macro" id="_M/MAX_GATHER_BATCH" data-ref="_M/MAX_GATHER_BATCH">MAX_GATHER_BATCH</dfn>	\</u></td></tr>
<tr><th id="209">209</th><td><u>	((PAGE_SIZE - sizeof(struct mmu_gather_batch)) / sizeof(void *))</u></td></tr>
<tr><th id="210">210</th><td></td></tr>
<tr><th id="211">211</th><td><i>/*</i></td></tr>
<tr><th id="212">212</th><td><i> * Limit the maximum number of mmu_gather batches to reduce a risk of soft</i></td></tr>
<tr><th id="213">213</th><td><i> * lockups for non-preemptible kernels on huge machines when a lot of memory</i></td></tr>
<tr><th id="214">214</th><td><i> * is zapped during unmapping.</i></td></tr>
<tr><th id="215">215</th><td><i> * 10K pages freed at once should be safe even without a preemption point.</i></td></tr>
<tr><th id="216">216</th><td><i> */</i></td></tr>
<tr><th id="217">217</th><td><u>#define <dfn class="macro" id="_M/MAX_GATHER_BATCH_COUNT" data-ref="_M/MAX_GATHER_BATCH_COUNT">MAX_GATHER_BATCH_COUNT</dfn>	(10000UL/MAX_GATHER_BATCH)</u></td></tr>
<tr><th id="218">218</th><td></td></tr>
<tr><th id="219">219</th><td><b>extern</b> <a class="typedef" href="../linux/types.h.html#bool" title='bool' data-type='_Bool' data-ref="bool" data-ref-filename="bool">bool</a> <dfn class="decl fn" id="__tlb_remove_page_size" title='__tlb_remove_page_size' data-ref="__tlb_remove_page_size" data-ref-filename="__tlb_remove_page_size">__tlb_remove_page_size</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col3 decl" id="14333tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14333tlb" data-ref-filename="14333tlb">tlb</dfn>, <b>struct</b> <a class="type" href="../linux/mm_types.h.html#page" title='page' data-ref="page" data-ref-filename="page">page</a> *<dfn class="local col4 decl" id="14334page" title='page' data-type='struct page *' data-ref="14334page" data-ref-filename="14334page">page</dfn>,</td></tr>
<tr><th id="220">220</th><td>				   <em>int</em> <dfn class="local col5 decl" id="14335page_size" title='page_size' data-type='int' data-ref="14335page_size" data-ref-filename="14335page_size">page_size</dfn>);</td></tr>
<tr><th id="221">221</th><td><u>#<span data-ppcond="194">endif</span></u></td></tr>
<tr><th id="222">222</th><td></td></tr>
<tr><th id="223">223</th><td><i>/*</i></td></tr>
<tr><th id="224">224</th><td><i> * struct mmu_gather is an opaque type used by the mm code for passing around</i></td></tr>
<tr><th id="225">225</th><td><i> * any data needed by arch specific code for tlb_remove_page.</i></td></tr>
<tr><th id="226">226</th><td><i> */</i></td></tr>
<tr><th id="227">227</th><td><b>struct</b> <dfn class="type def" id="mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</dfn> {</td></tr>
<tr><th id="228">228</th><td>	<b>struct</b> <a class="type" href="../linux/mm_types.h.html#mm_struct" title='mm_struct' data-ref="mm_struct" data-ref-filename="mm_struct">mm_struct</a>	*<dfn class="decl field" id="mmu_gather::mm" title='mmu_gather::mm' data-ref="mmu_gather::mm" data-ref-filename="mmu_gather..mm">mm</dfn>;</td></tr>
<tr><th id="229">229</th><td></td></tr>
<tr><th id="230">230</th><td><u>#<span data-ppcond="230">ifdef</span> <span class="macro" data-ref="_M/CONFIG_HAVE_RCU_TABLE_FREE">CONFIG_HAVE_RCU_TABLE_FREE</span></u></td></tr>
<tr><th id="231">231</th><td>	<b>struct</b> mmu_table_batch	*batch;</td></tr>
<tr><th id="232">232</th><td><u>#<span data-ppcond="230">endif</span></u></td></tr>
<tr><th id="233">233</th><td></td></tr>
<tr><th id="234">234</th><td>	<em>unsigned</em> <em>long</em>		<dfn class="decl field" id="mmu_gather::start" title='mmu_gather::start' data-ref="mmu_gather::start" data-ref-filename="mmu_gather..start">start</dfn>;</td></tr>
<tr><th id="235">235</th><td>	<em>unsigned</em> <em>long</em>		<dfn class="decl field" id="mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</dfn>;</td></tr>
<tr><th id="236">236</th><td>	<i>/*</i></td></tr>
<tr><th id="237">237</th><td><i>	 * we are in the middle of an operation to clear</i></td></tr>
<tr><th id="238">238</th><td><i>	 * a full mm and can make some optimizations</i></td></tr>
<tr><th id="239">239</th><td><i>	 */</i></td></tr>
<tr><th id="240">240</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::fullmm" title='mmu_gather::fullmm' data-ref="mmu_gather::fullmm" data-ref-filename="mmu_gather..fullmm">fullmm</dfn> : <var>1</var>;</td></tr>
<tr><th id="241">241</th><td></td></tr>
<tr><th id="242">242</th><td>	<i>/*</i></td></tr>
<tr><th id="243">243</th><td><i>	 * we have performed an operation which</i></td></tr>
<tr><th id="244">244</th><td><i>	 * requires a complete flush of the tlb</i></td></tr>
<tr><th id="245">245</th><td><i>	 */</i></td></tr>
<tr><th id="246">246</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::need_flush_all" title='mmu_gather::need_flush_all' data-ref="mmu_gather::need_flush_all" data-ref-filename="mmu_gather..need_flush_all">need_flush_all</dfn> : <var>1</var>;</td></tr>
<tr><th id="247">247</th><td></td></tr>
<tr><th id="248">248</th><td>	<i>/*</i></td></tr>
<tr><th id="249">249</th><td><i>	 * we have removed page directories</i></td></tr>
<tr><th id="250">250</th><td><i>	 */</i></td></tr>
<tr><th id="251">251</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::freed_tables" title='mmu_gather::freed_tables' data-ref="mmu_gather::freed_tables" data-ref-filename="mmu_gather..freed_tables">freed_tables</dfn> : <var>1</var>;</td></tr>
<tr><th id="252">252</th><td></td></tr>
<tr><th id="253">253</th><td>	<i>/*</i></td></tr>
<tr><th id="254">254</th><td><i>	 * at which levels have we cleared entries?</i></td></tr>
<tr><th id="255">255</th><td><i>	 */</i></td></tr>
<tr><th id="256">256</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::cleared_ptes" title='mmu_gather::cleared_ptes' data-ref="mmu_gather::cleared_ptes" data-ref-filename="mmu_gather..cleared_ptes">cleared_ptes</dfn> : <var>1</var>;</td></tr>
<tr><th id="257">257</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::cleared_pmds" title='mmu_gather::cleared_pmds' data-ref="mmu_gather::cleared_pmds" data-ref-filename="mmu_gather..cleared_pmds">cleared_pmds</dfn> : <var>1</var>;</td></tr>
<tr><th id="258">258</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::cleared_puds" title='mmu_gather::cleared_puds' data-ref="mmu_gather::cleared_puds" data-ref-filename="mmu_gather..cleared_puds">cleared_puds</dfn> : <var>1</var>;</td></tr>
<tr><th id="259">259</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::cleared_p4ds" title='mmu_gather::cleared_p4ds' data-ref="mmu_gather::cleared_p4ds" data-ref-filename="mmu_gather..cleared_p4ds">cleared_p4ds</dfn> : <var>1</var>;</td></tr>
<tr><th id="260">260</th><td></td></tr>
<tr><th id="261">261</th><td>	<i>/*</i></td></tr>
<tr><th id="262">262</th><td><i>	 * tracks VM_EXEC | VM_HUGETLB in tlb_start_vma</i></td></tr>
<tr><th id="263">263</th><td><i>	 */</i></td></tr>
<tr><th id="264">264</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::vma_exec" title='mmu_gather::vma_exec' data-ref="mmu_gather::vma_exec" data-ref-filename="mmu_gather..vma_exec">vma_exec</dfn> : <var>1</var>;</td></tr>
<tr><th id="265">265</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::vma_huge" title='mmu_gather::vma_huge' data-ref="mmu_gather::vma_huge" data-ref-filename="mmu_gather..vma_huge">vma_huge</dfn> : <var>1</var>;</td></tr>
<tr><th id="266">266</th><td></td></tr>
<tr><th id="267">267</th><td>	<em>unsigned</em> <em>int</em>		<dfn class="decl field" id="mmu_gather::batch_count" title='mmu_gather::batch_count' data-ref="mmu_gather::batch_count" data-ref-filename="mmu_gather..batch_count">batch_count</dfn>;</td></tr>
<tr><th id="268">268</th><td></td></tr>
<tr><th id="269">269</th><td><u>#<span data-ppcond="269">ifndef</span> <span class="macro" data-ref="_M/CONFIG_HAVE_MMU_GATHER_NO_GATHER">CONFIG_HAVE_MMU_GATHER_NO_GATHER</span></u></td></tr>
<tr><th id="270">270</th><td>	<b>struct</b> <a class="type" href="#mmu_gather_batch" title='mmu_gather_batch' data-ref="mmu_gather_batch" data-ref-filename="mmu_gather_batch">mmu_gather_batch</a> *<dfn class="decl field" id="mmu_gather::active" title='mmu_gather::active' data-ref="mmu_gather::active" data-ref-filename="mmu_gather..active">active</dfn>;</td></tr>
<tr><th id="271">271</th><td>	<b>struct</b> <a class="type" href="#mmu_gather_batch" title='mmu_gather_batch' data-ref="mmu_gather_batch" data-ref-filename="mmu_gather_batch">mmu_gather_batch</a>	<dfn class="decl field" id="mmu_gather::local" title='mmu_gather::local' data-ref="mmu_gather::local" data-ref-filename="mmu_gather..local">local</dfn>;</td></tr>
<tr><th id="272">272</th><td>	<b>struct</b> <a class="type" href="../linux/mm_types.h.html#page" title='page' data-ref="page" data-ref-filename="page">page</a>		*<dfn class="decl field" id="mmu_gather::__pages" title='mmu_gather::__pages' data-ref="mmu_gather::__pages" data-ref-filename="mmu_gather..__pages">__pages</dfn>[<a class="macro" href="#199" title="8" data-ref="_M/MMU_GATHER_BUNDLE">MMU_GATHER_BUNDLE</a>];</td></tr>
<tr><th id="273">273</th><td></td></tr>
<tr><th id="274">274</th><td><u>#<span data-ppcond="274">ifdef</span> <span class="macro" data-ref="_M/CONFIG_HAVE_MMU_GATHER_PAGE_SIZE">CONFIG_HAVE_MMU_GATHER_PAGE_SIZE</span></u></td></tr>
<tr><th id="275">275</th><td>	<em>unsigned</em> <em>int</em> page_size;</td></tr>
<tr><th id="276">276</th><td><u>#<span data-ppcond="274">endif</span></u></td></tr>
<tr><th id="277">277</th><td><u>#<span data-ppcond="269">endif</span></u></td></tr>
<tr><th id="278">278</th><td>};</td></tr>
<tr><th id="279">279</th><td></td></tr>
<tr><th id="280">280</th><td><em>void</em> <dfn class="decl fn" id="arch_tlb_gather_mmu" title='arch_tlb_gather_mmu' data-ref="arch_tlb_gather_mmu" data-ref-filename="arch_tlb_gather_mmu">arch_tlb_gather_mmu</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col6 decl" id="14336tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14336tlb" data-ref-filename="14336tlb">tlb</dfn>,</td></tr>
<tr><th id="281">281</th><td>	<b>struct</b> <a class="type" href="../linux/mm_types.h.html#mm_struct" title='mm_struct' data-ref="mm_struct" data-ref-filename="mm_struct">mm_struct</a> *<dfn class="local col7 decl" id="14337mm" title='mm' data-type='struct mm_struct *' data-ref="14337mm" data-ref-filename="14337mm">mm</dfn>, <em>unsigned</em> <em>long</em> <dfn class="local col8 decl" id="14338start" title='start' data-type='unsigned long' data-ref="14338start" data-ref-filename="14338start">start</dfn>, <em>unsigned</em> <em>long</em> <dfn class="local col9 decl" id="14339end" title='end' data-type='unsigned long' data-ref="14339end" data-ref-filename="14339end">end</dfn>);</td></tr>
<tr><th id="282">282</th><td><em>void</em> <dfn class="decl fn" id="tlb_flush_mmu" title='tlb_flush_mmu' data-ref="tlb_flush_mmu" data-ref-filename="tlb_flush_mmu">tlb_flush_mmu</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col0 decl" id="14340tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14340tlb" data-ref-filename="14340tlb">tlb</dfn>);</td></tr>
<tr><th id="283">283</th><td><em>void</em> <dfn class="decl fn" id="arch_tlb_finish_mmu" title='arch_tlb_finish_mmu' data-ref="arch_tlb_finish_mmu" data-ref-filename="arch_tlb_finish_mmu">arch_tlb_finish_mmu</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col1 decl" id="14341tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14341tlb" data-ref-filename="14341tlb">tlb</dfn>,</td></tr>
<tr><th id="284">284</th><td>			 <em>unsigned</em> <em>long</em> <dfn class="local col2 decl" id="14342start" title='start' data-type='unsigned long' data-ref="14342start" data-ref-filename="14342start">start</dfn>, <em>unsigned</em> <em>long</em> <dfn class="local col3 decl" id="14343end" title='end' data-type='unsigned long' data-ref="14343end" data-ref-filename="14343end">end</dfn>, <a class="typedef" href="../linux/types.h.html#bool" title='bool' data-type='_Bool' data-ref="bool" data-ref-filename="bool">bool</a> <dfn class="local col4 decl" id="14344force" title='force' data-type='bool' data-ref="14344force" data-ref-filename="14344force">force</dfn>);</td></tr>
<tr><th id="285">285</th><td></td></tr>
<tr><th id="286">286</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em> <dfn class="decl def fn" id="__tlb_adjust_range" title='__tlb_adjust_range' data-ref="__tlb_adjust_range" data-ref-filename="__tlb_adjust_range">__tlb_adjust_range</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col5 decl" id="14345tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14345tlb" data-ref-filename="14345tlb">tlb</dfn>,</td></tr>
<tr><th id="287">287</th><td>				      <em>unsigned</em> <em>long</em> <dfn class="local col6 decl" id="14346address" title='address' data-type='unsigned long' data-ref="14346address" data-ref-filename="14346address">address</dfn>,</td></tr>
<tr><th id="288">288</th><td>				      <em>unsigned</em> <em>int</em> <dfn class="local col7 decl" id="14347range_size" title='range_size' data-type='unsigned int' data-ref="14347range_size" data-ref-filename="14347range_size">range_size</dfn>)</td></tr>
<tr><th id="289">289</th><td>{</td></tr>
<tr><th id="290">290</th><td>	<a class="local col5 ref" href="#14345tlb" title='tlb' data-ref="14345tlb" data-ref-filename="14345tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::start" title='mmu_gather::start' data-ref="mmu_gather::start" data-ref-filename="mmu_gather..start">start</a> = <a class="macro" href="../linux/kernel.h.html#854" title="__builtin_choose_expr(((!!(sizeof((typeof(tlb-&gt;start) *)1 == (typeof(address) *)1))) &amp;&amp; ((sizeof(int) == sizeof(*(8 ? ((void *)((long)(tlb-&gt;start) * 0l)) : (int *)8))) &amp;&amp; (sizeof(int) == sizeof(*(8 ? ((void *)((long)(address) * 0l)) : (int *)8))))), ((tlb-&gt;start) &lt; (address) ? (tlb-&gt;start) : (address)), ({ typeof(tlb-&gt;start) __UNIQUE_ID___x180 = (tlb-&gt;start); typeof(address) __UNIQUE_ID___y181 = (address); ((__UNIQUE_ID___x180) &lt; (__UNIQUE_ID___y181) ? (__UNIQUE_ID___x180) : (__UNIQUE_ID___y181)); }))" data-ref="_M/min">min</a>(<a class="local col5 ref" href="#14345tlb" title='tlb' data-ref="14345tlb" data-ref-filename="14345tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::start" title='mmu_gather::start' data-ref="mmu_gather::start" data-ref-filename="mmu_gather..start">start</a>, <a class="local col6 ref" href="#14346address" title='address' data-ref="14346address" data-ref-filename="14346address">address</a>);</td></tr>
<tr><th id="291">291</th><td>	<a class="local col5 ref" href="#14345tlb" title='tlb' data-ref="14345tlb" data-ref-filename="14345tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</a> = <a class="macro" href="../linux/kernel.h.html#861" title="__builtin_choose_expr(((!!(sizeof((typeof(tlb-&gt;end) *)1 == (typeof(address + range_size) *)1))) &amp;&amp; ((sizeof(int) == sizeof(*(8 ? ((void *)((long)(tlb-&gt;end) * 0l)) : (int *)8))) &amp;&amp; (sizeof(int) == sizeof(*(8 ? ((void *)((long)(address + range_size) * 0l)) : (int *)8))))), ((tlb-&gt;end) &gt; (address + range_size) ? (tlb-&gt;end) : (address + range_size)), ({ typeof(tlb-&gt;end) __UNIQUE_ID___x184 = (tlb-&gt;end); typeof(address + range_size) __UNIQUE_ID___y185 = (address + range_size); ((__UNIQUE_ID___x184) &gt; (__UNIQUE_ID___y185) ? (__UNIQUE_ID___x184) : (__UNIQUE_ID___y185)); }))" data-ref="_M/max">max</a>(<a class="local col5 ref" href="#14345tlb" title='tlb' data-ref="14345tlb" data-ref-filename="14345tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</a>, <a class="local col6 ref" href="#14346address" title='address' data-ref="14346address" data-ref-filename="14346address">address</a> + <a class="local col7 ref" href="#14347range_size" title='range_size' data-ref="14347range_size" data-ref-filename="14347range_size">range_size</a>);</td></tr>
<tr><th id="292">292</th><td>}</td></tr>
<tr><th id="293">293</th><td></td></tr>
<tr><th id="294">294</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em> <dfn class="decl def fn" id="__tlb_reset_range" title='__tlb_reset_range' data-ref="__tlb_reset_range" data-ref-filename="__tlb_reset_range">__tlb_reset_range</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col8 decl" id="14348tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</dfn>)</td></tr>
<tr><th id="295">295</th><td>{</td></tr>
<tr><th id="296">296</th><td>	<b>if</b> (<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::fullmm" title='mmu_gather::fullmm' data-ref="mmu_gather::fullmm" data-ref-filename="mmu_gather..fullmm">fullmm</a>) {</td></tr>
<tr><th id="297">297</th><td>		<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::start" title='mmu_gather::start' data-ref="mmu_gather::start" data-ref-filename="mmu_gather..start">start</a> = <a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</a> = ~<var>0</var>;</td></tr>
<tr><th id="298">298</th><td>	} <b>else</b> {</td></tr>
<tr><th id="299">299</th><td>		<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::start" title='mmu_gather::start' data-ref="mmu_gather::start" data-ref-filename="mmu_gather..start">start</a> = <a class="macro" href="../../arch/x86/include/asm/processor.h.html#881" title="(test_ti_thread_flag(((struct thread_info *)get_current()), 29) ? ((get_current()-&gt;personality &amp; ADDR_LIMIT_3GB) ? 0xc0000000 : 0xFFFFe000) : ((1UL &lt;&lt; 47) - ((1UL) &lt;&lt; 12)))" data-ref="_M/TASK_SIZE">TASK_SIZE</a>;</td></tr>
<tr><th id="300">300</th><td>		<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</a> = <var>0</var>;</td></tr>
<tr><th id="301">301</th><td>	}</td></tr>
<tr><th id="302">302</th><td>	<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::freed_tables" title='mmu_gather::freed_tables' data-ref="mmu_gather::freed_tables" data-ref-filename="mmu_gather..freed_tables">freed_tables</a> = <var>0</var>;</td></tr>
<tr><th id="303">303</th><td>	<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_ptes" title='mmu_gather::cleared_ptes' data-ref="mmu_gather::cleared_ptes" data-ref-filename="mmu_gather..cleared_ptes">cleared_ptes</a> = <var>0</var>;</td></tr>
<tr><th id="304">304</th><td>	<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_pmds" title='mmu_gather::cleared_pmds' data-ref="mmu_gather::cleared_pmds" data-ref-filename="mmu_gather..cleared_pmds">cleared_pmds</a> = <var>0</var>;</td></tr>
<tr><th id="305">305</th><td>	<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_puds" title='mmu_gather::cleared_puds' data-ref="mmu_gather::cleared_puds" data-ref-filename="mmu_gather..cleared_puds">cleared_puds</a> = <var>0</var>;</td></tr>
<tr><th id="306">306</th><td>	<a class="local col8 ref" href="#14348tlb" title='tlb' data-ref="14348tlb" data-ref-filename="14348tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_p4ds" title='mmu_gather::cleared_p4ds' data-ref="mmu_gather::cleared_p4ds" data-ref-filename="mmu_gather..cleared_p4ds">cleared_p4ds</a> = <var>0</var>;</td></tr>
<tr><th id="307">307</th><td>	<i>/*</i></td></tr>
<tr><th id="308">308</th><td><i>	 * Do not reset mmu_gather::vma_* fields here, we do not</i></td></tr>
<tr><th id="309">309</th><td><i>	 * call into tlb_start_vma() again to set them if there is an</i></td></tr>
<tr><th id="310">310</th><td><i>	 * intermediate flush.</i></td></tr>
<tr><th id="311">311</th><td><i>	 */</i></td></tr>
<tr><th id="312">312</th><td>}</td></tr>
<tr><th id="313">313</th><td></td></tr>
<tr><th id="314">314</th><td><u>#<span data-ppcond="314">ifdef</span> <span class="macro" data-ref="_M/CONFIG_MMU_GATHER_NO_RANGE">CONFIG_MMU_GATHER_NO_RANGE</span></u></td></tr>
<tr><th id="315">315</th><td></td></tr>
<tr><th id="316">316</th><td><u>#if defined(tlb_flush) || defined(tlb_start_vma) || defined(tlb_end_vma)</u></td></tr>
<tr><th id="317">317</th><td><u>#error MMU_GATHER_NO_RANGE relies on default tlb_flush(), tlb_start_vma() and tlb_end_vma()</u></td></tr>
<tr><th id="318">318</th><td><u>#endif</u></td></tr>
<tr><th id="319">319</th><td></td></tr>
<tr><th id="320">320</th><td><i>/*</i></td></tr>
<tr><th id="321">321</th><td><i> * When an architecture does not have efficient means of range flushing TLBs</i></td></tr>
<tr><th id="322">322</th><td><i> * there is no point in doing intermediate flushes on tlb_end_vma() to keep the</i></td></tr>
<tr><th id="323">323</th><td><i> * range small. We equally don't have to worry about page granularity or other</i></td></tr>
<tr><th id="324">324</th><td><i> * things.</i></td></tr>
<tr><th id="325">325</th><td><i> *</i></td></tr>
<tr><th id="326">326</th><td><i> * All we need to do is issue a full flush for any !0 range.</i></td></tr>
<tr><th id="327">327</th><td><i> */</i></td></tr>
<tr><th id="328">328</th><td><em>static</em> <b>inline</b> <em>void</em> tlb_flush(<b>struct</b> mmu_gather *tlb)</td></tr>
<tr><th id="329">329</th><td>{</td></tr>
<tr><th id="330">330</th><td>	<b>if</b> (tlb-&gt;end)</td></tr>
<tr><th id="331">331</th><td>		flush_tlb_mm(tlb-&gt;mm);</td></tr>
<tr><th id="332">332</th><td>}</td></tr>
<tr><th id="333">333</th><td></td></tr>
<tr><th id="334">334</th><td><em>static</em> <b>inline</b> <em>void</em></td></tr>
<tr><th id="335">335</th><td>tlb_update_vma_flags(<b>struct</b> mmu_gather *tlb, <b>struct</b> vm_area_struct *vma) { }</td></tr>
<tr><th id="336">336</th><td></td></tr>
<tr><th id="337">337</th><td><u>#define tlb_end_vma tlb_end_vma</u></td></tr>
<tr><th id="338">338</th><td><em>static</em> <b>inline</b> <em>void</em> tlb_end_vma(<b>struct</b> mmu_gather *tlb, <b>struct</b> vm_area_struct *vma) { }</td></tr>
<tr><th id="339">339</th><td></td></tr>
<tr><th id="340">340</th><td><u>#<span data-ppcond="314">else</span> /* CONFIG_MMU_GATHER_NO_RANGE */</u></td></tr>
<tr><th id="341">341</th><td></td></tr>
<tr><th id="342">342</th><td><u>#<span data-ppcond="342">ifndef</span> <a class="macro" href="../../arch/x86/include/asm/tlb.h.html#9" data-ref="_M/tlb_flush">tlb_flush</a></u></td></tr>
<tr><th id="343">343</th><td></td></tr>
<tr><th id="344">344</th><td><u>#if defined(tlb_start_vma) || defined(tlb_end_vma)</u></td></tr>
<tr><th id="345">345</th><td><u>#error Default tlb_flush() relies on default tlb_start_vma() and tlb_end_vma()</u></td></tr>
<tr><th id="346">346</th><td><u>#endif</u></td></tr>
<tr><th id="347">347</th><td></td></tr>
<tr><th id="348">348</th><td><i>/*</i></td></tr>
<tr><th id="349">349</th><td><i> * When an architecture does not provide its own tlb_flush() implementation</i></td></tr>
<tr><th id="350">350</th><td><i> * but does have a reasonably efficient flush_vma_range() implementation</i></td></tr>
<tr><th id="351">351</th><td><i> * use that.</i></td></tr>
<tr><th id="352">352</th><td><i> */</i></td></tr>
<tr><th id="353">353</th><td><em>static</em> <b>inline</b> <em>void</em> tlb_flush(<b>struct</b> mmu_gather *tlb)</td></tr>
<tr><th id="354">354</th><td>{</td></tr>
<tr><th id="355">355</th><td>	<b>if</b> (tlb-&gt;fullmm || tlb-&gt;need_flush_all) {</td></tr>
<tr><th id="356">356</th><td>		flush_tlb_mm(tlb-&gt;mm);</td></tr>
<tr><th id="357">357</th><td>	} <b>else</b> <b>if</b> (tlb-&gt;end) {</td></tr>
<tr><th id="358">358</th><td>		<b>struct</b> vm_area_struct vma = {</td></tr>
<tr><th id="359">359</th><td>			.vm_mm = tlb-&gt;mm,</td></tr>
<tr><th id="360">360</th><td>			.vm_flags = (tlb-&gt;vma_exec ? VM_EXEC    : <var>0</var>) |</td></tr>
<tr><th id="361">361</th><td>				    (tlb-&gt;vma_huge ? VM_HUGETLB : <var>0</var>),</td></tr>
<tr><th id="362">362</th><td>		};</td></tr>
<tr><th id="363">363</th><td></td></tr>
<tr><th id="364">364</th><td>		flush_tlb_range(&amp;vma, tlb-&gt;start, tlb-&gt;end);</td></tr>
<tr><th id="365">365</th><td>	}</td></tr>
<tr><th id="366">366</th><td>}</td></tr>
<tr><th id="367">367</th><td></td></tr>
<tr><th id="368">368</th><td><em>static</em> <b>inline</b> <em>void</em></td></tr>
<tr><th id="369">369</th><td>tlb_update_vma_flags(<b>struct</b> mmu_gather *tlb, <b>struct</b> vm_area_struct *vma)</td></tr>
<tr><th id="370">370</th><td>{</td></tr>
<tr><th id="371">371</th><td>	<i>/*</i></td></tr>
<tr><th id="372">372</th><td><i>	 * flush_tlb_range() implementations that look at VM_HUGETLB (tile,</i></td></tr>
<tr><th id="373">373</th><td><i>	 * mips-4k) flush only large pages.</i></td></tr>
<tr><th id="374">374</th><td><i>	 *</i></td></tr>
<tr><th id="375">375</th><td><i>	 * flush_tlb_range() implementations that flush I-TLB also flush D-TLB</i></td></tr>
<tr><th id="376">376</th><td><i>	 * (tile, xtensa, arm), so it's ok to just add VM_EXEC to an existing</i></td></tr>
<tr><th id="377">377</th><td><i>	 * range.</i></td></tr>
<tr><th id="378">378</th><td><i>	 *</i></td></tr>
<tr><th id="379">379</th><td><i>	 * We rely on tlb_end_vma() to issue a flush, such that when we reset</i></td></tr>
<tr><th id="380">380</th><td><i>	 * these values the batch is empty.</i></td></tr>
<tr><th id="381">381</th><td><i>	 */</i></td></tr>
<tr><th id="382">382</th><td>	tlb-&gt;vma_huge = !!(vma-&gt;vm_flags &amp; VM_HUGETLB);</td></tr>
<tr><th id="383">383</th><td>	tlb-&gt;vma_exec = !!(vma-&gt;vm_flags &amp; VM_EXEC);</td></tr>
<tr><th id="384">384</th><td>}</td></tr>
<tr><th id="385">385</th><td></td></tr>
<tr><th id="386">386</th><td><u>#<span data-ppcond="342">else</span></u></td></tr>
<tr><th id="387">387</th><td></td></tr>
<tr><th id="388">388</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em></td></tr>
<tr><th id="389">389</th><td><dfn class="decl def fn" id="tlb_update_vma_flags" title='tlb_update_vma_flags' data-ref="tlb_update_vma_flags" data-ref-filename="tlb_update_vma_flags">tlb_update_vma_flags</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col9 decl" id="14349tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14349tlb" data-ref-filename="14349tlb">tlb</dfn>, <b>struct</b> <a class="type" href="../linux/mm_types.h.html#vm_area_struct" title='vm_area_struct' data-ref="vm_area_struct" data-ref-filename="vm_area_struct">vm_area_struct</a> *<dfn class="local col0 decl" id="14350vma" title='vma' data-type='struct vm_area_struct *' data-ref="14350vma" data-ref-filename="14350vma">vma</dfn>) { }</td></tr>
<tr><th id="390">390</th><td></td></tr>
<tr><th id="391">391</th><td><u>#<span data-ppcond="342">endif</span></u></td></tr>
<tr><th id="392">392</th><td></td></tr>
<tr><th id="393">393</th><td><u>#<span data-ppcond="314">endif</span> /* CONFIG_MMU_GATHER_NO_RANGE */</u></td></tr>
<tr><th id="394">394</th><td></td></tr>
<tr><th id="395">395</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em> <dfn class="decl def fn" id="tlb_flush_mmu_tlbonly" title='tlb_flush_mmu_tlbonly' data-ref="tlb_flush_mmu_tlbonly" data-ref-filename="tlb_flush_mmu_tlbonly">tlb_flush_mmu_tlbonly</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col1 decl" id="14351tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</dfn>)</td></tr>
<tr><th id="396">396</th><td>{</td></tr>
<tr><th id="397">397</th><td>	<b>if</b> (!<a class="local col1 ref" href="#14351tlb" title='tlb' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</a>)</td></tr>
<tr><th id="398">398</th><td>		<b>return</b>;</td></tr>
<tr><th id="399">399</th><td></td></tr>
<tr><th id="400">400</th><td>	<a class="macro" href="../../arch/x86/include/asm/tlb.h.html#9" title="tlb_flush" data-ref="_M/tlb_flush">tlb_flush</a>(<a class="local col1 ref" href="#14351tlb" title='tlb' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</a>);</td></tr>
<tr><th id="401">401</th><td>	<a class="ref fn" href="../linux/mmu_notifier.h.html#mmu_notifier_invalidate_range" title='mmu_notifier_invalidate_range' data-ref="mmu_notifier_invalidate_range" data-ref-filename="mmu_notifier_invalidate_range">mmu_notifier_invalidate_range</a>(<a class="local col1 ref" href="#14351tlb" title='tlb' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::mm" title='mmu_gather::mm' data-ref="mmu_gather::mm" data-ref-filename="mmu_gather..mm">mm</a>, <a class="local col1 ref" href="#14351tlb" title='tlb' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::start" title='mmu_gather::start' data-ref="mmu_gather::start" data-ref-filename="mmu_gather..start">start</a>, <a class="local col1 ref" href="#14351tlb" title='tlb' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::end" title='mmu_gather::end' data-ref="mmu_gather::end" data-ref-filename="mmu_gather..end">end</a>);</td></tr>
<tr><th id="402">402</th><td>	<a class="ref fn" href="#__tlb_reset_range" title='__tlb_reset_range' data-ref="__tlb_reset_range" data-ref-filename="__tlb_reset_range">__tlb_reset_range</a>(<a class="local col1 ref" href="#14351tlb" title='tlb' data-ref="14351tlb" data-ref-filename="14351tlb">tlb</a>);</td></tr>
<tr><th id="403">403</th><td>}</td></tr>
<tr><th id="404">404</th><td></td></tr>
<tr><th id="405">405</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em> <dfn class="decl def fn" id="tlb_remove_page_size" title='tlb_remove_page_size' data-ref="tlb_remove_page_size" data-ref-filename="tlb_remove_page_size">tlb_remove_page_size</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col2 decl" id="14352tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14352tlb" data-ref-filename="14352tlb">tlb</dfn>,</td></tr>
<tr><th id="406">406</th><td>					<b>struct</b> <a class="type" href="../linux/mm_types.h.html#page" title='page' data-ref="page" data-ref-filename="page">page</a> *<dfn class="local col3 decl" id="14353page" title='page' data-type='struct page *' data-ref="14353page" data-ref-filename="14353page">page</dfn>, <em>int</em> <dfn class="local col4 decl" id="14354page_size" title='page_size' data-type='int' data-ref="14354page_size" data-ref-filename="14354page_size">page_size</dfn>)</td></tr>
<tr><th id="407">407</th><td>{</td></tr>
<tr><th id="408">408</th><td>	<b>if</b> (<a class="ref fn" href="#__tlb_remove_page_size" title='__tlb_remove_page_size' data-ref="__tlb_remove_page_size" data-ref-filename="__tlb_remove_page_size">__tlb_remove_page_size</a>(<a class="local col2 ref" href="#14352tlb" title='tlb' data-ref="14352tlb" data-ref-filename="14352tlb">tlb</a>, <a class="local col3 ref" href="#14353page" title='page' data-ref="14353page" data-ref-filename="14353page">page</a>, <a class="local col4 ref" href="#14354page_size" title='page_size' data-ref="14354page_size" data-ref-filename="14354page_size">page_size</a>))</td></tr>
<tr><th id="409">409</th><td>		<a class="ref fn" href="#tlb_flush_mmu" title='tlb_flush_mmu' data-ref="tlb_flush_mmu" data-ref-filename="tlb_flush_mmu">tlb_flush_mmu</a>(<a class="local col2 ref" href="#14352tlb" title='tlb' data-ref="14352tlb" data-ref-filename="14352tlb">tlb</a>);</td></tr>
<tr><th id="410">410</th><td>}</td></tr>
<tr><th id="411">411</th><td></td></tr>
<tr><th id="412">412</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <a class="typedef" href="../linux/types.h.html#bool" title='bool' data-type='_Bool' data-ref="bool" data-ref-filename="bool">bool</a> <dfn class="decl def fn" id="__tlb_remove_page" title='__tlb_remove_page' data-ref="__tlb_remove_page" data-ref-filename="__tlb_remove_page">__tlb_remove_page</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col5 decl" id="14355tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14355tlb" data-ref-filename="14355tlb">tlb</dfn>, <b>struct</b> <a class="type" href="../linux/mm_types.h.html#page" title='page' data-ref="page" data-ref-filename="page">page</a> *<dfn class="local col6 decl" id="14356page" title='page' data-type='struct page *' data-ref="14356page" data-ref-filename="14356page">page</dfn>)</td></tr>
<tr><th id="413">413</th><td>{</td></tr>
<tr><th id="414">414</th><td>	<b>return</b> <a class="ref fn" href="#__tlb_remove_page_size" title='__tlb_remove_page_size' data-ref="__tlb_remove_page_size" data-ref-filename="__tlb_remove_page_size">__tlb_remove_page_size</a>(<a class="local col5 ref" href="#14355tlb" title='tlb' data-ref="14355tlb" data-ref-filename="14355tlb">tlb</a>, <a class="local col6 ref" href="#14356page" title='page' data-ref="14356page" data-ref-filename="14356page">page</a>, <a class="macro" href="../../arch/x86/include/asm/page_types.h.html#11" title="((1UL) &lt;&lt; 12)" data-ref="_M/PAGE_SIZE">PAGE_SIZE</a>);</td></tr>
<tr><th id="415">415</th><td>}</td></tr>
<tr><th id="416">416</th><td></td></tr>
<tr><th id="417">417</th><td><i>/* tlb_remove_page</i></td></tr>
<tr><th id="418">418</th><td><i> *	Similar to __tlb_remove_page but will call tlb_flush_mmu() itself when</i></td></tr>
<tr><th id="419">419</th><td><i> *	required.</i></td></tr>
<tr><th id="420">420</th><td><i> */</i></td></tr>
<tr><th id="421">421</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em> <dfn class="decl def fn" id="tlb_remove_page" title='tlb_remove_page' data-ref="tlb_remove_page" data-ref-filename="tlb_remove_page">tlb_remove_page</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col7 decl" id="14357tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14357tlb" data-ref-filename="14357tlb">tlb</dfn>, <b>struct</b> <a class="type" href="../linux/mm_types.h.html#page" title='page' data-ref="page" data-ref-filename="page">page</a> *<dfn class="local col8 decl" id="14358page" title='page' data-type='struct page *' data-ref="14358page" data-ref-filename="14358page">page</dfn>)</td></tr>
<tr><th id="422">422</th><td>{</td></tr>
<tr><th id="423">423</th><td>	<b>return</b> <a class="ref fn" href="#tlb_remove_page_size" title='tlb_remove_page_size' data-ref="tlb_remove_page_size" data-ref-filename="tlb_remove_page_size">tlb_remove_page_size</a>(<a class="local col7 ref" href="#14357tlb" title='tlb' data-ref="14357tlb" data-ref-filename="14357tlb">tlb</a>, <a class="local col8 ref" href="#14358page" title='page' data-ref="14358page" data-ref-filename="14358page">page</a>, <a class="macro" href="../../arch/x86/include/asm/page_types.h.html#11" title="((1UL) &lt;&lt; 12)" data-ref="_M/PAGE_SIZE">PAGE_SIZE</a>);</td></tr>
<tr><th id="424">424</th><td>}</td></tr>
<tr><th id="425">425</th><td></td></tr>
<tr><th id="426">426</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>void</em> <dfn class="decl def fn" id="tlb_change_page_size" title='tlb_change_page_size' data-ref="tlb_change_page_size" data-ref-filename="tlb_change_page_size">tlb_change_page_size</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col9 decl" id="14359tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14359tlb" data-ref-filename="14359tlb">tlb</dfn>,</td></tr>
<tr><th id="427">427</th><td>						     <em>unsigned</em> <em>int</em> <dfn class="local col0 decl" id="14360page_size" title='page_size' data-type='unsigned int' data-ref="14360page_size" data-ref-filename="14360page_size">page_size</dfn>)</td></tr>
<tr><th id="428">428</th><td>{</td></tr>
<tr><th id="429">429</th><td><u>#<span data-ppcond="429">ifdef</span> <span class="macro" data-ref="_M/CONFIG_HAVE_MMU_GATHER_PAGE_SIZE">CONFIG_HAVE_MMU_GATHER_PAGE_SIZE</span></u></td></tr>
<tr><th id="430">430</th><td>	<b>if</b> (tlb-&gt;page_size &amp;&amp; tlb-&gt;page_size != page_size) {</td></tr>
<tr><th id="431">431</th><td>		<b>if</b> (!tlb-&gt;fullmm)</td></tr>
<tr><th id="432">432</th><td>			tlb_flush_mmu(tlb);</td></tr>
<tr><th id="433">433</th><td>	}</td></tr>
<tr><th id="434">434</th><td></td></tr>
<tr><th id="435">435</th><td>	tlb-&gt;page_size = page_size;</td></tr>
<tr><th id="436">436</th><td><u>#<span data-ppcond="429">endif</span></u></td></tr>
<tr><th id="437">437</th><td>}</td></tr>
<tr><th id="438">438</th><td></td></tr>
<tr><th id="439">439</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>unsigned</em> <em>long</em> <dfn class="decl def fn" id="tlb_get_unmap_shift" title='tlb_get_unmap_shift' data-ref="tlb_get_unmap_shift" data-ref-filename="tlb_get_unmap_shift">tlb_get_unmap_shift</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col1 decl" id="14361tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14361tlb" data-ref-filename="14361tlb">tlb</dfn>)</td></tr>
<tr><th id="440">440</th><td>{</td></tr>
<tr><th id="441">441</th><td>	<b>if</b> (<a class="local col1 ref" href="#14361tlb" title='tlb' data-ref="14361tlb" data-ref-filename="14361tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_ptes" title='mmu_gather::cleared_ptes' data-ref="mmu_gather::cleared_ptes" data-ref-filename="mmu_gather..cleared_ptes">cleared_ptes</a>)</td></tr>
<tr><th id="442">442</th><td>		<b>return</b> <a class="macro" href="../../arch/x86/include/asm/page_types.h.html#10" title="12" data-ref="_M/PAGE_SHIFT">PAGE_SHIFT</a>;</td></tr>
<tr><th id="443">443</th><td>	<b>if</b> (<a class="local col1 ref" href="#14361tlb" title='tlb' data-ref="14361tlb" data-ref-filename="14361tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_pmds" title='mmu_gather::cleared_pmds' data-ref="mmu_gather::cleared_pmds" data-ref-filename="mmu_gather..cleared_pmds">cleared_pmds</a>)</td></tr>
<tr><th id="444">444</th><td>		<b>return</b> <a class="macro" href="../../arch/x86/include/asm/pgtable_64_types.h.html#90" title="21" data-ref="_M/PMD_SHIFT">PMD_SHIFT</a>;</td></tr>
<tr><th id="445">445</th><td>	<b>if</b> (<a class="local col1 ref" href="#14361tlb" title='tlb' data-ref="14361tlb" data-ref-filename="14361tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_puds" title='mmu_gather::cleared_puds' data-ref="mmu_gather::cleared_puds" data-ref-filename="mmu_gather..cleared_puds">cleared_puds</a>)</td></tr>
<tr><th id="446">446</th><td>		<b>return</b> <a class="macro" href="../../arch/x86/include/asm/pgtable_64_types.h.html#83" title="30" data-ref="_M/PUD_SHIFT">PUD_SHIFT</a>;</td></tr>
<tr><th id="447">447</th><td>	<b>if</b> (<a class="local col1 ref" href="#14361tlb" title='tlb' data-ref="14361tlb" data-ref-filename="14361tlb">tlb</a>-&gt;<a class="ref field" href="#mmu_gather::cleared_p4ds" title='mmu_gather::cleared_p4ds' data-ref="mmu_gather::cleared_p4ds" data-ref-filename="mmu_gather..cleared_p4ds">cleared_p4ds</a>)</td></tr>
<tr><th id="448">448</th><td>		<b>return</b> <a class="macro" href="pgtable-nop4d.h.html#11" title="39" data-ref="_M/P4D_SHIFT">P4D_SHIFT</a>;</td></tr>
<tr><th id="449">449</th><td></td></tr>
<tr><th id="450">450</th><td>	<b>return</b> <a class="macro" href="../../arch/x86/include/asm/page_types.h.html#10" title="12" data-ref="_M/PAGE_SHIFT">PAGE_SHIFT</a>;</td></tr>
<tr><th id="451">451</th><td>}</td></tr>
<tr><th id="452">452</th><td></td></tr>
<tr><th id="453">453</th><td><em>static</em> <a class="macro" href="../linux/compiler_types.h.html#149" title="inline __attribute__((__gnu_inline__)) __attribute__((__unused__)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a> <em>unsigned</em> <em>long</em> <dfn class="decl def fn" id="tlb_get_unmap_size" title='tlb_get_unmap_size' data-ref="tlb_get_unmap_size" data-ref-filename="tlb_get_unmap_size">tlb_get_unmap_size</dfn>(<b>struct</b> <a class="type" href="#mmu_gather" title='mmu_gather' data-ref="mmu_gather" data-ref-filename="mmu_gather">mmu_gather</a> *<dfn class="local col2 decl" id="14362tlb" title='tlb' data-type='struct mmu_gather *' data-ref="14362tlb" data-ref-filename="14362tlb">tlb</dfn>)</td></tr>
<tr><th id="454">454</th><td>{</td></tr>
<tr><th id="455">455</th><td>	<b>return</b> <var>1UL</var> &lt;&lt; <a class="ref fn" href="#tlb_get_unmap_shift" title='tlb_get_unmap_shift' data-ref="tlb_get_unmap_shift" data-ref-filename="tlb_get_unmap_shift">tlb_get_unmap_shift</a>(<a class="local col2 ref" href="#14362tlb" title='tlb' data-ref="14362tlb" data-ref-filename="14362tlb">tlb</a>);</td></tr>
<tr><th id="456">456</th><td>}</td></tr>
<tr><th id="457">457</th><td></td></tr>
<tr><th id="458">458</th><td><i>/*</i></td></tr>
<tr><th id="459">459</th><td><i> * In the case of tlb vma handling, we can optimise these away in the</i></td></tr>
<tr><th id="460">460</th><td><i> * case where we're doing a full MM flush.  When we're doing a munmap,</i></td></tr>
<tr><th id="461">461</th><td><i> * the vmas are adjusted to only cover the region to be torn down.</i></td></tr>
<tr><th id="462">462</th><td><i> */</i></td></tr>
<tr><th id="463">463</th><td><u>#<span data-ppcond="463">ifndef</span> <a class="macro" href="../../arch/x86/include/asm/tlb.h.html#5" data-ref="_M/tlb_start_vma">tlb_start_vma</a></u></td></tr>
<tr><th id="464">464</th><td><em>static</em> <b>inline</b> <em>void</em> tlb_start_vma(<b>struct</b> mmu_gather *tlb, <b>struct</b> vm_area_struct *vma)</td></tr>
<tr><th id="465">465</th><td>{</td></tr>
<tr><th id="466">466</th><td>	<b>if</b> (tlb-&gt;fullmm)</td></tr>
<tr><th id="467">467</th><td>		<b>return</b>;</td></tr>
<tr><th id="468">468</th><td></td></tr>
<tr><th id="469">469</th><td>	tlb_update_vma_flags(tlb, vma);</td></tr>
<tr><th id="470">470</th><td>	flush_cache_range(vma, vma-&gt;vm_start, vma-&gt;vm_end);</td></tr>
<tr><th id="471">471</th><td>}</td></tr>
<tr><th id="472">472</th><td><u>#<span data-ppcond="463">endif</span></u></td></tr>
<tr><th id="473">473</th><td></td></tr>
<tr><th id="474">474</th><td><u>#<span data-ppcond="474">ifndef</span> <a class="macro" href="../../arch/x86/include/asm/tlb.h.html#6" data-ref="_M/tlb_end_vma">tlb_end_vma</a></u></td></tr>
<tr><th id="475">475</th><td><em>static</em> <b>inline</b> <em>void</em> tlb_end_vma(<b>struct</b> mmu_gather *tlb, <b>struct</b> vm_area_struct *vma)</td></tr>
<tr><th id="476">476</th><td>{</td></tr>
<tr><th id="477">477</th><td>	<b>if</b> (tlb-&gt;fullmm)</td></tr>
<tr><th id="478">478</th><td>		<b>return</b>;</td></tr>
<tr><th id="479">479</th><td></td></tr>
<tr><th id="480">480</th><td>	<i>/*</i></td></tr>
<tr><th id="481">481</th><td><i>	 * Do a TLB flush and reset the range at VMA boundaries; this avoids</i></td></tr>
<tr><th id="482">482</th><td><i>	 * the ranges growing with the unused space between consecutive VMAs,</i></td></tr>
<tr><th id="483">483</th><td><i>	 * but also the mmu_gather::vma_* flags from tlb_start_vma() rely on</i></td></tr>
<tr><th id="484">484</th><td><i>	 * this.</i></td></tr>
<tr><th id="485">485</th><td><i>	 */</i></td></tr>
<tr><th id="486">486</th><td>	tlb_flush_mmu_tlbonly(tlb);</td></tr>
<tr><th id="487">487</th><td>}</td></tr>
<tr><th id="488">488</th><td><u>#<span data-ppcond="474">endif</span></u></td></tr>
<tr><th id="489">489</th><td></td></tr>
<tr><th id="490">490</th><td><u>#<span data-ppcond="490">ifndef</span> <a class="macro" href="../../arch/x86/include/asm/tlb.h.html#7" data-ref="_M/__tlb_remove_tlb_entry">__tlb_remove_tlb_entry</a></u></td></tr>
<tr><th id="491">491</th><td><u>#define __tlb_remove_tlb_entry(tlb, ptep, address) do { } while (0)</u></td></tr>
<tr><th id="492">492</th><td><u>#<span data-ppcond="490">endif</span></u></td></tr>
<tr><th id="493">493</th><td></td></tr>
<tr><th id="494">494</th><td><i class="doc">/**</i></td></tr>
<tr><th id="495">495</th><td><i class="doc"> * tlb_remove_tlb_entry - remember a pte unmapping for later tlb invalidation.</i></td></tr>
<tr><th id="496">496</th><td><i class="doc"> *</i></td></tr>
<tr><th id="497">497</th><td><i class="doc"> * Record the fact that pte's were really unmapped by updating the range,</i></td></tr>
<tr><th id="498">498</th><td><i class="doc"> * so we can later optimise away the tlb invalidate.   This helps when</i></td></tr>
<tr><th id="499">499</th><td><i class="doc"> * userspace is unmapping already-unmapped pages, which happens quite a lot.</i></td></tr>
<tr><th id="500">500</th><td><i class="doc"> */</i></td></tr>
<tr><th id="501">501</th><td><u>#define <dfn class="macro" id="_M/tlb_remove_tlb_entry" data-ref="_M/tlb_remove_tlb_entry">tlb_remove_tlb_entry</dfn>(tlb, ptep, address)		\</u></td></tr>
<tr><th id="502">502</th><td><u>	do {							\</u></td></tr>
<tr><th id="503">503</th><td><u>		__tlb_adjust_range(tlb, address, PAGE_SIZE);	\</u></td></tr>
<tr><th id="504">504</th><td><u>		tlb-&gt;cleared_ptes = 1;				\</u></td></tr>
<tr><th id="505">505</th><td><u>		__tlb_remove_tlb_entry(tlb, ptep, address);	\</u></td></tr>
<tr><th id="506">506</th><td><u>	} while (0)</u></td></tr>
<tr><th id="507">507</th><td></td></tr>
<tr><th id="508">508</th><td><u>#define <dfn class="macro" id="_M/tlb_remove_huge_tlb_entry" data-ref="_M/tlb_remove_huge_tlb_entry">tlb_remove_huge_tlb_entry</dfn>(h, tlb, ptep, address)	\</u></td></tr>
<tr><th id="509">509</th><td><u>	do {							\</u></td></tr>
<tr><th id="510">510</th><td><u>		unsigned long _sz = huge_page_size(h);		\</u></td></tr>
<tr><th id="511">511</th><td><u>		__tlb_adjust_range(tlb, address, _sz);		\</u></td></tr>
<tr><th id="512">512</th><td><u>		if (_sz == PMD_SIZE)				\</u></td></tr>
<tr><th id="513">513</th><td><u>			tlb-&gt;cleared_pmds = 1;			\</u></td></tr>
<tr><th id="514">514</th><td><u>		else if (_sz == PUD_SIZE)			\</u></td></tr>
<tr><th id="515">515</th><td><u>			tlb-&gt;cleared_puds = 1;			\</u></td></tr>
<tr><th id="516">516</th><td><u>		__tlb_remove_tlb_entry(tlb, ptep, address);	\</u></td></tr>
<tr><th id="517">517</th><td><u>	} while (0)</u></td></tr>
<tr><th id="518">518</th><td></td></tr>
<tr><th id="519">519</th><td><i class="doc">/**</i></td></tr>
<tr><th id="520">520</th><td><i class="doc"> * tlb_remove_pmd_tlb_entry - remember a pmd mapping for later tlb invalidation</i></td></tr>
<tr><th id="521">521</th><td><i class="doc"> * This is a nop so far, because only x86 needs it.</i></td></tr>
<tr><th id="522">522</th><td><i class="doc"> */</i></td></tr>
<tr><th id="523">523</th><td><u>#<span data-ppcond="523">ifndef</span> <span class="macro" data-ref="_M/__tlb_remove_pmd_tlb_entry">__tlb_remove_pmd_tlb_entry</span></u></td></tr>
<tr><th id="524">524</th><td><u>#define <dfn class="macro" id="_M/__tlb_remove_pmd_tlb_entry" data-ref="_M/__tlb_remove_pmd_tlb_entry">__tlb_remove_pmd_tlb_entry</dfn>(tlb, pmdp, address) do {} while (0)</u></td></tr>
<tr><th id="525">525</th><td><u>#<span data-ppcond="523">endif</span></u></td></tr>
<tr><th id="526">526</th><td></td></tr>
<tr><th id="527">527</th><td><u>#define <dfn class="macro" id="_M/tlb_remove_pmd_tlb_entry" data-ref="_M/tlb_remove_pmd_tlb_entry">tlb_remove_pmd_tlb_entry</dfn>(tlb, pmdp, address)			\</u></td></tr>
<tr><th id="528">528</th><td><u>	do {								\</u></td></tr>
<tr><th id="529">529</th><td><u>		__tlb_adjust_range(tlb, address, HPAGE_PMD_SIZE);	\</u></td></tr>
<tr><th id="530">530</th><td><u>		tlb-&gt;cleared_pmds = 1;					\</u></td></tr>
<tr><th id="531">531</th><td><u>		__tlb_remove_pmd_tlb_entry(tlb, pmdp, address);		\</u></td></tr>
<tr><th id="532">532</th><td><u>	} while (0)</u></td></tr>
<tr><th id="533">533</th><td></td></tr>
<tr><th id="534">534</th><td><i class="doc">/**</i></td></tr>
<tr><th id="535">535</th><td><i class="doc"> * tlb_remove_pud_tlb_entry - remember a pud mapping for later tlb</i></td></tr>
<tr><th id="536">536</th><td><i class="doc"> * invalidation. This is a nop so far, because only x86 needs it.</i></td></tr>
<tr><th id="537">537</th><td><i class="doc"> */</i></td></tr>
<tr><th id="538">538</th><td><u>#<span data-ppcond="538">ifndef</span> <span class="macro" data-ref="_M/__tlb_remove_pud_tlb_entry">__tlb_remove_pud_tlb_entry</span></u></td></tr>
<tr><th id="539">539</th><td><u>#define <dfn class="macro" id="_M/__tlb_remove_pud_tlb_entry" data-ref="_M/__tlb_remove_pud_tlb_entry">__tlb_remove_pud_tlb_entry</dfn>(tlb, pudp, address) do {} while (0)</u></td></tr>
<tr><th id="540">540</th><td><u>#<span data-ppcond="538">endif</span></u></td></tr>
<tr><th id="541">541</th><td></td></tr>
<tr><th id="542">542</th><td><u>#define <dfn class="macro" id="_M/tlb_remove_pud_tlb_entry" data-ref="_M/tlb_remove_pud_tlb_entry">tlb_remove_pud_tlb_entry</dfn>(tlb, pudp, address)			\</u></td></tr>
<tr><th id="543">543</th><td><u>	do {								\</u></td></tr>
<tr><th id="544">544</th><td><u>		__tlb_adjust_range(tlb, address, HPAGE_PUD_SIZE);	\</u></td></tr>
<tr><th id="545">545</th><td><u>		tlb-&gt;cleared_puds = 1;					\</u></td></tr>
<tr><th id="546">546</th><td><u>		__tlb_remove_pud_tlb_entry(tlb, pudp, address);		\</u></td></tr>
<tr><th id="547">547</th><td><u>	} while (0)</u></td></tr>
<tr><th id="548">548</th><td></td></tr>
<tr><th id="549">549</th><td><i>/*</i></td></tr>
<tr><th id="550">550</th><td><i> * For things like page tables caches (ie caching addresses "inside" the</i></td></tr>
<tr><th id="551">551</th><td><i> * page tables, like x86 does), for legacy reasons, flushing an</i></td></tr>
<tr><th id="552">552</th><td><i> * individual page had better flush the page table caches behind it. This</i></td></tr>
<tr><th id="553">553</th><td><i> * is definitely how x86 works, for example. And if you have an</i></td></tr>
<tr><th id="554">554</th><td><i> * architected non-legacy page table cache (which I'm not aware of</i></td></tr>
<tr><th id="555">555</th><td><i> * anybody actually doing), you're going to have some architecturally</i></td></tr>
<tr><th id="556">556</th><td><i> * explicit flushing for that, likely *separate* from a regular TLB entry</i></td></tr>
<tr><th id="557">557</th><td><i> * flush, and thus you'd need more than just some range expansion..</i></td></tr>
<tr><th id="558">558</th><td><i> *</i></td></tr>
<tr><th id="559">559</th><td><i> * So if we ever find an architecture</i></td></tr>
<tr><th id="560">560</th><td><i> * that would want something that odd, I think it is up to that</i></td></tr>
<tr><th id="561">561</th><td><i> * architecture to do its own odd thing, not cause pain for others</i></td></tr>
<tr><th id="562">562</th><td><i> * <a href="http://lkml.kernel.org/r/CA+55aFzBggoXtNXQeng5d_mRoDnaMBE5Y+URs+PHR67nUpMtaw@mail.gmail.com">http://lkml.kernel.org/r/CA+55aFzBggoXtNXQeng5d_mRoDnaMBE5Y+URs+PHR67nUpMtaw@mail.gmail.com</a></i></td></tr>
<tr><th id="563">563</th><td><i> *</i></td></tr>
<tr><th id="564">564</th><td><i> * For now w.r.t page table cache, mark the range_size as PAGE_SIZE</i></td></tr>
<tr><th id="565">565</th><td><i> */</i></td></tr>
<tr><th id="566">566</th><td></td></tr>
<tr><th id="567">567</th><td><u>#<span data-ppcond="567">ifndef</span> <span class="macro" data-ref="_M/pte_free_tlb">pte_free_tlb</span></u></td></tr>
<tr><th id="568">568</th><td><u>#define <dfn class="macro" id="_M/pte_free_tlb" data-ref="_M/pte_free_tlb">pte_free_tlb</dfn>(tlb, ptep, address)			\</u></td></tr>
<tr><th id="569">569</th><td><u>	do {							\</u></td></tr>
<tr><th id="570">570</th><td><u>		__tlb_adjust_range(tlb, address, PAGE_SIZE);	\</u></td></tr>
<tr><th id="571">571</th><td><u>		tlb-&gt;freed_tables = 1;				\</u></td></tr>
<tr><th id="572">572</th><td><u>		tlb-&gt;cleared_pmds = 1;				\</u></td></tr>
<tr><th id="573">573</th><td><u>		__pte_free_tlb(tlb, ptep, address);		\</u></td></tr>
<tr><th id="574">574</th><td><u>	} while (0)</u></td></tr>
<tr><th id="575">575</th><td><u>#<span data-ppcond="567">endif</span></u></td></tr>
<tr><th id="576">576</th><td></td></tr>
<tr><th id="577">577</th><td><u>#<span data-ppcond="577">ifndef</span> <span class="macro" data-ref="_M/pmd_free_tlb">pmd_free_tlb</span></u></td></tr>
<tr><th id="578">578</th><td><u>#define <dfn class="macro" id="_M/pmd_free_tlb" data-ref="_M/pmd_free_tlb">pmd_free_tlb</dfn>(tlb, pmdp, address)			\</u></td></tr>
<tr><th id="579">579</th><td><u>	do {							\</u></td></tr>
<tr><th id="580">580</th><td><u>		__tlb_adjust_range(tlb, address, PAGE_SIZE);	\</u></td></tr>
<tr><th id="581">581</th><td><u>		tlb-&gt;freed_tables = 1;				\</u></td></tr>
<tr><th id="582">582</th><td><u>		tlb-&gt;cleared_puds = 1;				\</u></td></tr>
<tr><th id="583">583</th><td><u>		__pmd_free_tlb(tlb, pmdp, address);		\</u></td></tr>
<tr><th id="584">584</th><td><u>	} while (0)</u></td></tr>
<tr><th id="585">585</th><td><u>#<span data-ppcond="577">endif</span></u></td></tr>
<tr><th id="586">586</th><td></td></tr>
<tr><th id="587">587</th><td><u>#<span data-ppcond="587">ifndef</span> <span class="macro" data-ref="_M/__ARCH_HAS_4LEVEL_HACK">__ARCH_HAS_4LEVEL_HACK</span></u></td></tr>
<tr><th id="588">588</th><td><u>#<span data-ppcond="588">ifndef</span> <span class="macro" data-ref="_M/pud_free_tlb">pud_free_tlb</span></u></td></tr>
<tr><th id="589">589</th><td><u>#define <dfn class="macro" id="_M/pud_free_tlb" data-ref="_M/pud_free_tlb">pud_free_tlb</dfn>(tlb, pudp, address)			\</u></td></tr>
<tr><th id="590">590</th><td><u>	do {							\</u></td></tr>
<tr><th id="591">591</th><td><u>		__tlb_adjust_range(tlb, address, PAGE_SIZE);	\</u></td></tr>
<tr><th id="592">592</th><td><u>		tlb-&gt;freed_tables = 1;				\</u></td></tr>
<tr><th id="593">593</th><td><u>		tlb-&gt;cleared_p4ds = 1;				\</u></td></tr>
<tr><th id="594">594</th><td><u>		__pud_free_tlb(tlb, pudp, address);		\</u></td></tr>
<tr><th id="595">595</th><td><u>	} while (0)</u></td></tr>
<tr><th id="596">596</th><td><u>#<span data-ppcond="588">endif</span></u></td></tr>
<tr><th id="597">597</th><td><u>#<span data-ppcond="587">endif</span></u></td></tr>
<tr><th id="598">598</th><td></td></tr>
<tr><th id="599">599</th><td><u>#<span data-ppcond="599">ifndef</span> <span class="macro" data-ref="_M/__ARCH_HAS_5LEVEL_HACK">__ARCH_HAS_5LEVEL_HACK</span></u></td></tr>
<tr><th id="600">600</th><td><u>#<span data-ppcond="600">ifndef</span> <span class="macro" data-ref="_M/p4d_free_tlb">p4d_free_tlb</span></u></td></tr>
<tr><th id="601">601</th><td><u>#define <dfn class="macro" id="_M/p4d_free_tlb" data-ref="_M/p4d_free_tlb">p4d_free_tlb</dfn>(tlb, pudp, address)			\</u></td></tr>
<tr><th id="602">602</th><td><u>	do {							\</u></td></tr>
<tr><th id="603">603</th><td><u>		__tlb_adjust_range(tlb, address, PAGE_SIZE);	\</u></td></tr>
<tr><th id="604">604</th><td><u>		tlb-&gt;freed_tables = 1;				\</u></td></tr>
<tr><th id="605">605</th><td><u>		__p4d_free_tlb(tlb, pudp, address);		\</u></td></tr>
<tr><th id="606">606</th><td><u>	} while (0)</u></td></tr>
<tr><th id="607">607</th><td><u>#<span data-ppcond="600">endif</span></u></td></tr>
<tr><th id="608">608</th><td><u>#<span data-ppcond="599">endif</span></u></td></tr>
<tr><th id="609">609</th><td></td></tr>
<tr><th id="610">610</th><td><u>#<span data-ppcond="29">endif</span> /* CONFIG_MMU */</u></td></tr>
<tr><th id="611">611</th><td></td></tr>
<tr><th id="612">612</th><td><u>#<span data-ppcond="11">endif</span> /* _ASM_GENERIC__TLB_H */</u></td></tr>
<tr><th id="613">613</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../../arch/x86/boot/compressed/acpi.c.html'>linux-5.3.1/arch/x86/boot/compressed/acpi.c</a><br/>Generated on <em>2020-Jun-10</em> from project linux-5.3.1 revision <em>5.3.1</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
