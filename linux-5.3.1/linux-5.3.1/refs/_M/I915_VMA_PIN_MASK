<dec f='linux-5.3.1/drivers/gpu/drm/i915/i915_vma.h' l='99'/>
<use f='linux-5.3.1/drivers/gpu/drm/i915/i915_vma.h' l='337' u='c'/>
<doc f='linux-5.3.1/drivers/gpu/drm/i915/i915_vma.h' l='76'>/**
	 * How many users have pinned this object in GTT space.
	 *
	 * This is a tightly bound, fairly small number of users, so we
	 * stuff inside the flags field so that we can both check for overflow
	 * and detect a no-op i915_vma_pin() in a single check, while also
	 * pinning the vma.
	 *
	 * The worst case display setup would have the same vma pinned for
	 * use on each plane on each crtc, while also building the next atomic
	 * state and holding a pin for the length of the cleanup queue. In the
	 * future, the flip queue may be increased from 1.
	 * Estimated worst case: 3 [qlen] * 4 [max crtcs] * 7 [max planes] = 84
	 *
	 * For GEM, the number of concurrent users for pwrite/pread is
	 * unbounded. For execbuffer, it is currently one but will in future
	 * be extended to allow multiple clients to pin vma concurrently.
	 *
	 * We also use suballocated pages, with each suballocation claiming
	 * its own pin on the shared vma. At present, this is limited to
	 * exclusive cachelines of a single page, so a maximum of 64 possible
	 * users.
	 */</doc>
<use f='linux-5.3.1/drivers/gpu/drm/i915/gem/i915_gem_object.c' l='166' u='c'/>
