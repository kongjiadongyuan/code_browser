<dec f='linux-5.3.1/include/linux/sched.h' l='1781' type='int __cond_resched_lock(spinlock_t * lock)'/>
<use f='linux-5.3.1/fs/jbd2/commit.c' l='1031' macro='1' u='c' c='jbd2_journal_commit_transaction'/>
<def f='linux-5.3.1/kernel/sched/core.c' l='5443' ll='5460' type='int __cond_resched_lock(spinlock_t * lock)'/>
<dec f='linux-5.3.1/kernel/sched/core.c' l='5461' type='int __cond_resched_lock(spinlock_t * )'/>
<use f='linux-5.3.1/kernel/sched/core.c' l='5461' c='__cond_resched_lock'/>
<use f='linux-5.3.1/kernel/sched/core.c' l='5461' u='a'/>
<doc f='linux-5.3.1/kernel/sched/core.c' l='5435'>/*
 * __cond_resched_lock() - if a reschedule is pending, drop the given lock,
 * call schedule, and on return reacquire the lock.
 *
 * This works OK both with and without CONFIG_PREEMPT. We do strange low-level
 * operations here to prevent schedule() from being called twice (once via
 * spin_unlock(), once by hand).
 */</doc>
<use f='linux-5.3.1/mm/hugetlb.c' l='1866' macro='1' u='c' c='return_unused_surplus_pages'/>
<use f='linux-5.3.1/mm/hugetlb.c' l='2422' macro='1' u='c' c='set_max_huge_pages'/>
<use f='linux-5.3.1/mm/vmalloc.c' l='1289' macro='1' u='c' c='__purge_vmap_area_lazy'/>
