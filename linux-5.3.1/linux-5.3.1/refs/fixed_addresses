<def f='linux-5.3.1/arch/x86/include/asm/fixmap.h' l='76' ll='143'/>
<use f='linux-5.3.1/arch/x86/include/asm/fixmap.h' l='159' c='__native_set_fixmap'/>
<use f='linux-5.3.1/arch/x86/include/asm/fixmap.h' l='160' c='native_set_fixmap'/>
<use f='linux-5.3.1/arch/x86/include/asm/fixmap.h' l='164' c='__set_fixmap'/>
<use f='linux-5.3.1/arch/x86/include/asm/fixmap.h' l='196' c='__early_set_fixmap'/>
<doc f='linux-5.3.1/arch/x86/include/asm/fixmap.h' l='57'>/*
 * Here we define all the compile-time &apos;special&apos; virtual
 * addresses. The point is to have a constant address at
 * compile time, but to set the physical address only
 * in the boot process.
 * for x86_32: We allocate these special addresses
 * from the end of virtual memory (0xfffff000) backwards.
 * Also this lets us do fail-safe vmalloc(), we
 * can guarantee that these special addresses and
 * vmalloc()-ed addresses never overlap.
 *
 * These &apos;compile-time allocated&apos; memory buffers are
 * fixed-size 4k pages (or larger if used with an increment
 * higher than 1). Use set_fixmap(idx,phys) to associate
 * physical memory with fixmap indices.
 *
 * TLB entries of such buffers will not be flushed across
 * task switches.
 */</doc>
<use f='linux-5.3.1/arch/x86/mm/ioremap.c' l='840' c='__early_set_fixmap'/>
<use f='linux-5.3.1/arch/x86/mm/pgtable.c' l='629' c='__native_set_fixmap'/>
<use f='linux-5.3.1/arch/x86/mm/pgtable.c' l='650' c='native_set_fixmap'/>
<use f='linux-5.3.1/mm/early_ioremap.c' l='111' c='__early_ioremap'/>
<use f='linux-5.3.1/mm/early_ioremap.c' l='173' c='early_iounmap'/>
