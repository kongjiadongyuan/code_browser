<dec f='linux-5.3.1/include/linux/iomap.h' l='131' type='loff_t iomap_apply(struct inode * inode, loff_t pos, loff_t length, unsigned int flags, const struct iomap_ops * ops, void * data, iomap_actor_t actor)'/>
<def f='linux-5.3.1/fs/iomap/apply.c' l='22' ll='74' type='loff_t iomap_apply(struct inode * inode, loff_t pos, loff_t length, unsigned int flags, const struct iomap_ops * ops, void * data, iomap_actor_t actor)'/>
<doc f='linux-5.3.1/fs/iomap/apply.c' l='11'>/*
 * Execute a iomap write on a segment of the mapping that spans a
 * contiguous range of pages that have identical block mapping state.
 *
 * This avoids the need to map pages individually, do individual allocations
 * for each page and most importantly avoid the need for filesystem specific
 * locking per page. Instead, all the operations are amortised over the entire
 * range of pages. It is assumed that the filesystems will lock whatever
 * resources they require in the iomap_begin call, and release them in the
 * iomap_end call.
 */</doc>
<use f='linux-5.3.1/fs/iomap/buffered-io.c' l='297' u='c' c='iomap_readpage'/>
<use f='linux-5.3.1/fs/iomap/buffered-io.c' l='393' u='c' c='iomap_readpages'/>
<use f='linux-5.3.1/fs/iomap/buffered-io.c' l='826' u='c' c='iomap_file_buffered_write'/>
<use f='linux-5.3.1/fs/iomap/buffered-io.c' l='907' u='c' c='iomap_file_dirty'/>
<use f='linux-5.3.1/fs/iomap/buffered-io.c' l='985' u='c' c='iomap_zero_range'/>
<use f='linux-5.3.1/fs/iomap/buffered-io.c' l='1058' u='c' c='iomap_page_mkwrite'/>
<use f='linux-5.3.1/fs/iomap/direct-io.c' l='492' u='c' c='iomap_dio_rw'/>
<use f='linux-5.3.1/fs/iomap/fiemap.c' l='88' u='c' c='iomap_fiemap'/>
<use f='linux-5.3.1/fs/iomap/fiemap.c' l='141' u='c' c='iomap_bmap'/>
<use f='linux-5.3.1/fs/iomap/seek.c' l='151' u='c' c='iomap_seek_hole'/>
<use f='linux-5.3.1/fs/iomap/seek.c' l='197' u='c' c='iomap_seek_data'/>
<use f='linux-5.3.1/fs/iomap/swapfile.c' l='157' u='c' c='iomap_swapfile_activate'/>
