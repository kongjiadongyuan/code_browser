<dec f='linux-5.3.1/include/linux/vmalloc.h' l='200' type='struct vm_struct ** pcpu_get_vm_areas(const unsigned long * offsets, const size_t * sizes, int nr_vms, size_t align)'/>
<use f='linux-5.3.1/mm/percpu-vm.c' l='340' u='c' c='pcpu_create_chunk'/>
<def f='linux-5.3.1/mm/vmalloc.c' l='3204' ll='3391' type='struct vm_struct ** pcpu_get_vm_areas(const unsigned long * offsets, const size_t * sizes, int nr_vms, size_t align)'/>
<use f='linux-5.3.1/mm/vmalloc.c' l='3348' u='r' c='pcpu_get_vm_areas'/>
<doc f='linux-5.3.1/mm/vmalloc.c' l='3180'>/**
 * pcpu_get_vm_areas - allocate vmalloc areas for percpu allocator
 * @offsets: array containing offset of each area
 * @sizes: array containing size of each area
 * @nr_vms: the number of areas to allocate
 * @align: alignment, all entries in @offsets and @sizes must be aligned to this
 *
 * Returns: kmalloc&apos;d vm_struct pointer array pointing to allocated
 *	    vm_structs on success, %NULL on failure
 *
 * Percpu allocator wants to use congruent vm areas so that it can
 * maintain the offsets among percpu areas.  This function allocates
 * congruent vmalloc areas for it with GFP_KERNEL.  These areas tend to
 * be scattered pretty far, distance between two areas easily going up
 * to gigabytes.  To avoid interacting with regular vmallocs, these
 * areas are allocated from top.
 *
 * Despite its complicated look, this allocator is rather simple. It
 * does everything top-down and scans free blocks from the end looking
 * for matching base. While scanning, if any of the areas do not fit the
 * base address is pulled down to fit the area. Scanning is repeated till
 * all the areas fit and then all necessary data structures are inserted
 * and the result is returned.
 */</doc>
