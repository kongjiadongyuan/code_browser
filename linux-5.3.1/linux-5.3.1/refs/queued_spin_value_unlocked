<def f='linux-5.3.1/include/asm-generic/qspinlock.h' l='39' ll='42' type='int queued_spin_value_unlocked(struct qspinlock lock)'/>
<doc f='linux-5.3.1/include/asm-generic/qspinlock.h' l='29'>/**
 * queued_spin_value_unlocked - is the spinlock structure unlocked?
 * @lock: queued spinlock structure
 * Return: 1 if it is unlocked, 0 otherwise
 *
 * N.B. Whenever there are tasks waiting for the lock, it is considered
 *      locked wrt the lockref code to avoid lock stealing by the lockref
 *      code and change things underneath the lock. This also allows some
 *      optimizations to be applied without conflict with lockref.
 */</doc>
<use f='linux-5.3.1/lib/lockref.c' l='46' macro='1' u='c' c='lockref_get'/>
<use f='linux-5.3.1/lib/lockref.c' l='67' macro='1' u='c' c='lockref_get_not_zero'/>
<use f='linux-5.3.1/lib/lockref.c' l='95' macro='1' u='c' c='lockref_put_not_zero'/>
<use f='linux-5.3.1/lib/lockref.c' l='122' macro='1' u='c' c='lockref_get_or_lock'/>
<use f='linux-5.3.1/lib/lockref.c' l='148' macro='1' u='c' c='lockref_put_return'/>
<use f='linux-5.3.1/lib/lockref.c' l='166' macro='1' u='c' c='lockref_put_or_lock'/>
<use f='linux-5.3.1/lib/lockref.c' l='203' macro='1' u='c' c='lockref_get_not_dead'/>
