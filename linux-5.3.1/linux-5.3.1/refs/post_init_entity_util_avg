<dec f='linux-5.3.1/kernel/sched/sched.h' l='1846' type='void post_init_entity_util_avg(struct task_struct * p)'/>
<use f='linux-5.3.1/kernel/sched/core.c' l='2845' u='c' c='wake_up_new_task'/>
<def f='linux-5.3.1/kernel/sched/fair.c' l='781' ll='817' type='void post_init_entity_util_avg(struct task_struct * p)'/>
<doc f='linux-5.3.1/kernel/sched/fair.c' l='755'>/*
 * With new tasks being created, their initial util_avgs are extrapolated
 * based on the cfs_rq&apos;s current util_avg:
 *
 *   util_avg = cfs_rq-&gt;util_avg / (cfs_rq-&gt;load_avg + 1) * se.load.weight
 *
 * However, in many cases, the above util_avg does not give a desired
 * value. Moreover, the sum of the util_avgs may be divergent, such
 * as when the series is a harmonic series.
 *
 * To solve this problem, we also cap the util_avg of successive tasks to
 * only 1/2 of the left utilization budget:
 *
 *   util_avg_cap = (cpu_scale - cfs_rq-&gt;avg.util_avg) / 2^n
 *
 * where n denotes the nth task and cpu_scale the CPU capacity.
 *
 * For example, for a CPU with 1024 of capacity, a simplest series from
 * the beginning would be like:
 *
 *  task  util_avg: 512, 256, 128,  64,  32,   16,    8, ...
 * cfs_rq util_avg: 512, 768, 896, 960, 992, 1008, 1016, ...
 *
 * Finally, that extrapolated util_avg is clamped to the cap (util_avg_cap)
 * if util_avg &gt; util_avg_cap.
 */</doc>
