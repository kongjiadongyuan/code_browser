<dec f='linux-5.3.1/include/linux/blkdev.h' l='865' type='int blk_rq_map_user_iov(struct request_queue * , struct request * , struct rq_map_data * , const struct iov_iter * , gfp_t )'/>
<def f='linux-5.3.1/block/blk-map.c' l='120' ll='158' type='int blk_rq_map_user_iov(struct request_queue * q, struct request * rq, struct rq_map_data * map_data, const struct iov_iter * iter, gfp_t gfp_mask)'/>
<dec f='linux-5.3.1/block/blk-map.c' l='159' type='int blk_rq_map_user_iov(struct request_queue * , struct request * , struct rq_map_data * , const struct iov_iter * , gfp_t )'/>
<use f='linux-5.3.1/block/blk-map.c' l='159' c='blk_rq_map_user_iov'/>
<use f='linux-5.3.1/block/blk-map.c' l='159' u='a'/>
<use f='linux-5.3.1/block/blk-map.c' l='172' u='c' c='blk_rq_map_user'/>
<doc f='linux-5.3.1/block/blk-map.c' l='99'>/**
 * blk_rq_map_user_iov - map user data to a request, for passthrough requests
 * @q:		request queue where request should be inserted
 * @rq:		request to map data to
 * @map_data:   pointer to the rq_map_data holding pages (if necessary)
 * @iter:	iovec iterator
 * @gfp_mask:	memory allocation flags
 *
 * Description:
 *    Data will be mapped directly for zero copy I/O, if possible. Otherwise
 *    a kernel bounce buffer is used.
 *
 *    A matching blk_rq_unmap_user() must be issued at the end of I/O, while
 *    still in process context.
 *
 *    Note: The mapped bio may need to be bounced through blk_queue_bounce()
 *    before being submitted to the device, as pages mapped may be out of
 *    reach. It&apos;s the callers responsibility to make sure this happens. The
 *    original bio must be passed back in to blk_rq_unmap_user() for proper
 *    unmapping.
 */</doc>
<use f='linux-5.3.1/block/scsi_ioctl.c' l='339' u='c' c='sg_io'/>
<use f='linux-5.3.1/drivers/scsi/sg.c' l='1810' u='c' c='sg_start_req'/>
