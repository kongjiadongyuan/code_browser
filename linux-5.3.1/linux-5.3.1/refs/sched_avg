<def f='linux-5.3.1/include/linux/sched.h' l='409' ll='419'/>
<use f='linux-5.3.1/include/linux/sched.h' l='490'/>
<use f='linux-5.3.1/include/linux/sched.h' l='1992' c='sched_trace_cfs_rq_avg'/>
<use f='linux-5.3.1/include/linux/sched.h' l='1996' c='sched_trace_rq_avg_rt'/>
<use f='linux-5.3.1/include/linux/sched.h' l='1997' c='sched_trace_rq_avg_dl'/>
<use f='linux-5.3.1/include/linux/sched.h' l='1998' c='sched_trace_rq_avg_irq'/>
<size>64</size>
<doc f='linux-5.3.1/include/linux/sched.h' l='366'>/*
 * The load_avg/util_avg accumulates an infinite geometric series
 * (see __update_load_avg() in kernel/sched/fair.c).
 *
 * [load_avg definition]
 *
 *   load_avg = runnable% * scale_load_down(load)
 *
 * where runnable% is the time ratio that a sched_entity is runnable.
 * For cfs_rq, it is the aggregated load_avg of all runnable and
 * blocked sched_entities.
 *
 * [util_avg definition]
 *
 *   util_avg = running% * SCHED_CAPACITY_SCALE
 *
 * where running% is the time ratio that a sched_entity is running on
 * a CPU. For cfs_rq, it is the aggregated util_avg of all runnable
 * and blocked sched_entities.
 *
 * load_avg and util_avg don&apos;t direcly factor frequency scaling and CPU
 * capacity scaling. The scaling is done through the rq_clock_pelt that
 * is used for computing those signals (see update_rq_clock_pelt())
 *
 * N.B., the above ratios (runnable% and running%) themselves are in the
 * range of [0, 1]. To do fixed point arithmetics, we therefore scale them
 * to as large a range as necessary. This is for example reflected by
 * util_avg&apos;s SCHED_CAPACITY_SCALE.
 *
 * [Overflow issue]
 *
 * The 64-bit load_sum can have 4353082796 (=2^64/47742/88761) entities
 * with the highest load (=88761), always runnable on a single cfs_rq,
 * and should not overflow as the number already hits PID_MAX_LIMIT.
 *
 * For all other cases (including 32-bit kernels), struct load_weight&apos;s
 * weight will overflow first before we do, because:
 *
 *    Max(load_avg) &lt;= Max(load.weight)
 *
 * Then it is the load_weight&apos;s responsibility to consider overflow
 * issues.
 */</doc>
<mbr r='sched_avg::last_update_time' o='0' t='u64'/>
<mbr r='sched_avg::load_sum' o='64' t='u64'/>
<mbr r='sched_avg::runnable_load_sum' o='128' t='u64'/>
<mbr r='sched_avg::util_sum' o='192' t='u32'/>
<mbr r='sched_avg::period_contrib' o='224' t='u32'/>
<mbr r='sched_avg::load_avg' o='256' t='unsigned long'/>
<mbr r='sched_avg::runnable_load_avg' o='320' t='unsigned long'/>
<mbr r='sched_avg::util_avg' o='384' t='unsigned long'/>
<mbr r='sched_avg::util_est' o='448' t='struct util_est'/>
<use f='linux-5.3.1/kernel/sched/sched.h' l='513'/>
<use f='linux-5.3.1/kernel/sched/sched.h' l='934'/>
<use f='linux-5.3.1/kernel/sched/sched.h' l='935'/>
<size>64</size>
<use f='linux-5.3.1/kernel/sched/pelt.h' l='29' c='cfs_se_util_change'/>
<size>64</size>
<use f='linux-5.3.1/kernel/sched/fair.c' l='734' c='init_entity_runnable_average'/>
<use f='linux-5.3.1/kernel/sched/fair.c' l='785' c='post_init_entity_util_avg'/>
<use f='linux-5.3.1/kernel/sched/fair.c' l='3473' c='update_cfs_rq_load_avg'/>
<use f='linux-5.3.1/kernel/sched/fair.c' l='10544' c='sched_trace_cfs_rq_avg'/>
<use f='linux-5.3.1/kernel/sched/fair.c' l='10574' c='sched_trace_rq_avg_rt'/>
<use f='linux-5.3.1/kernel/sched/fair.c' l='10584' c='sched_trace_rq_avg_dl'/>
<use f='linux-5.3.1/kernel/sched/fair.c' l='10594' c='sched_trace_rq_avg_irq'/>
<size>64</size>
<use f='linux-5.3.1/kernel/sched/pelt.c' l='110' c='accumulate_sum'/>
<use f='linux-5.3.1/kernel/sched/pelt.c' l='176' c='___update_load_sum'/>
<use f='linux-5.3.1/kernel/sched/pelt.c' l='227' c='___update_load_avg'/>
<size>64</size>
