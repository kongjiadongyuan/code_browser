<def f='linux/kernel/locking/qspinlock.c' l='125' ll='149'/>
<use f='linux/kernel/locking/qspinlock.c' l='162' c='clear_pending_set_locked'/>
<use f='linux/kernel/locking/qspinlock.c' l='179' c='xchg_tail'/>
<use f='linux/kernel/locking/qspinlock.c' l='240' c='set_locked'/>
<size>4</size>
<doc f='linux/kernel/locking/qspinlock.c' l='117'>/*
 * By using the whole 2nd least significant byte for the pending bit, we
 * can allow better optimization of the lock acquisition for the pending
 * bit holder.
 *
 * This internal structure is also used by the set_locked function which
 * is not restricted to _Q_PENDING_BITS == 8.
 */</doc>
