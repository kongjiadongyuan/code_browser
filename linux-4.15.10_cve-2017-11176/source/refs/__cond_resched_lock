<dec f='linux/include/linux/sched.h' l='1574' type='int __cond_resched_lock(spinlock_t * lock)'/>
<use f='linux/fs/jbd2/commit.c' l='1017' macro='1' u='c' c='jbd2_journal_commit_transaction'/>
<def f='linux/kernel/sched/core.c' l='4868' ll='4885' type='int __cond_resched_lock(spinlock_t * lock)'/>
<dec f='linux/kernel/sched/core.c' l='4886' type='int __cond_resched_lock(spinlock_t * )'/>
<use f='linux/kernel/sched/core.c' l='4886' c='__cond_resched_lock'/>
<use f='linux/kernel/sched/core.c' l='4886' u='a'/>
<use f='linux/kernel/sched/core.c' l='4886' u='a'/>
<doc f='linux/kernel/sched/core.c' l='4860'>/*
 * __cond_resched_lock() - if a reschedule is pending, drop the given lock,
 * call schedule, and on return reacquire the lock.
 *
 * This works OK both with and without CONFIG_PREEMPT. We do strange low-level
 * operations here to prevent schedule() from being called twice (once via
 * spin_unlock(), once by hand).
 */</doc>
<use f='linux/mm/hugetlb.c' l='1806' macro='1' u='c' c='return_unused_surplus_pages'/>
<use f='linux/mm/hugetlb.c' l='2349' macro='1' u='c' c='set_max_huge_pages'/>
<use f='linux/mm/vmalloc.c' l='704' macro='1' u='c' c='__purge_vmap_area_lazy'/>
