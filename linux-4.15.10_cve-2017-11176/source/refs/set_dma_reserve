<dec f='linux/include/linux/mm.h' l='2071' type='void set_dma_reserve(unsigned long new_dma_reserve)'/>
<use f='linux/arch/x86/mm/init.c' l='842' u='c' c='memblock_find_dma_reserve'/>
<def f='linux/mm/page_alloc.c' l='6870' ll='6873' type='void set_dma_reserve(unsigned long new_dma_reserve)'/>
<doc f='linux/mm/page_alloc.c' l='6859'>/**
 * set_dma_reserve - set the specified number of pages reserved in the first zone
 * @new_dma_reserve: The number of pages to mark reserved
 *
 * The per-cpu batchsize and zone watermarks are determined by managed_pages.
 * In the DMA zone, a significant percentage may be consumed by kernel image
 * and other unfreeable allocations which can skew the watermarks badly. This
 * function may optionally be used to account for unfreeable pages in the
 * first zone (e.g., ZONE_DMA). The effect will be lower watermarks and
 * smaller per-cpu batchsize.
 */</doc>
