<dec f='linux/drivers/gpu/drm/i915/i915_gem_request.h' l='283' type='int i915_gem_request_await_object(struct drm_i915_gem_request * to, struct drm_i915_gem_object * obj, bool write)'/>
<use f='linux/drivers/gpu/drm/i915/i915_gem_execbuffer.c' l='1112' u='c' c='__reloc_gpu_alloc'/>
<use f='linux/drivers/gpu/drm/i915/i915_gem_execbuffer.c' l='1799' u='c' c='eb_move_to_gpu'/>
<def f='linux/drivers/gpu/drm/i915/i915_gem_request.c' l='867' ll='907' type='int i915_gem_request_await_object(struct drm_i915_gem_request * to, struct drm_i915_gem_object * obj, bool write)'/>
<doc f='linux/drivers/gpu/drm/i915/i915_gem_request.c' l='847'>/**
 * i915_gem_request_await_object - set this request to (async) wait upon a bo
 *
 * @to: request we are wishing to use
 * @obj: object which may be in use on another ring.
 *
 * This code is meant to abstract object synchronization with the GPU.
 * Conceptually we serialise writes between engines inside the GPU.
 * We only allow one engine to write into a buffer at any time, but
 * multiple readers. To ensure each has a coherent view of memory, we must:
 *
 * - If there is an outstanding write request to the object, the new
 *   request must wait for it to complete (either CPU or in hw, requests
 *   on the same ring will be naturally ordered).
 *
 * - If we are a write request (pending_write_domain is set), the new
 *   request must wait for outstanding read requests to complete.
 *
 * Returns 0 if successful, else propagates up the lower layer error.
 */</doc>
