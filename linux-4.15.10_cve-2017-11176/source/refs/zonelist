<def f='linux/include/linux/mmzone.h' l='605' ll='607'/>
<use f='linux/include/linux/mmzone.h' l='625'/>
<use f='linux/include/linux/mmzone.h' l='1009' c='first_zones_zonelist'/>
<use f='linux/include/linux/gfp.h' l='437' c='node_zonelist'/>
<use f='linux/include/linux/swap.h' l='349' c='try_to_free_pages'/>
<size>4112</size>
<doc f='linux/include/linux/mmzone.h' l='591'>/*
 * One allocation request operates on a zonelist. A zonelist
 * is a list of zones, the first one is the &apos;goal&apos; of the
 * allocation, the other zones are fallback zones, in decreasing
 * priority.
 *
 * To speed the reading of the zonelist, the zonerefs contain the zone index
 * of the entry being read. Helper functions to access information given
 * a struct zoneref are
 *
 * zonelist_zone()	- Return the struct zone * for an entry in _zonerefs
 * zonelist_zone_idx()	- Return the index of the zone for an entry
 * zonelist_node_idx()	- Return the index of the node for an entry
 */</doc>
<mbr r='zonelist::_zonerefs' o='0' t='struct zoneref [257]'/>
<use f='linux/include/linux/oom.h' l='24'/>
<size>4112</size>
<use f='linux/mm/internal.h' l='118'/>
<size>4112</size>
<use f='linux/mm/hugetlb.c' l='894' c='dequeue_huge_page_nodemask'/>
<size>4112</size>
<use f='linux/mm/mempolicy.c' l='1725' c='mempolicy_slab_node'/>
<size>4112</size>
<use f='linux/mm/mm_init.c' l='36' c='mminit_verify_zonelist'/>
<size>4112</size>
<use f='linux/mm/page_alloc.c' l='2176' c='unreserve_highatomic_pageblock'/>
<use f='linux/mm/page_alloc.c' l='4528' c='nr_free_zone_pages'/>
<size>4112</size>
<use f='linux/mm/slub.c' l='1860' c='get_any_partial'/>
<size>4112</size>
<use f='linux/mm/vmscan.c' l='2726' c='shrink_zones'/>
<use f='linux/mm/vmscan.c' l='2846' c='do_try_to_free_pages'/>
<use f='linux/mm/vmscan.c' l='2956' c='throttle_direct_reclaim'/>
<use f='linux/mm/vmscan.c' l='3040' c='try_to_free_pages'/>
<use f='linux/mm/vmscan.c' l='3674' c='shrink_all_memory'/>
<size>4112</size>
