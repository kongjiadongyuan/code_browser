<dec f='linux/crypto/internal.h' l='95' type='void * crypto_alloc_tfm(const char * alg_name, const struct crypto_type * frontend, u32 type, u32 mask)'/>
<use f='linux/crypto/acompress.c' l='117' u='c' c='crypto_alloc_acomp'/>
<use f='linux/crypto/aead.c' l='342' u='c' c='crypto_alloc_aead'/>
<use f='linux/crypto/ahash.c' l='552' u='c' c='crypto_alloc_ahash'/>
<use f='linux/crypto/akcipher.c' l='112' u='c' c='crypto_alloc_akcipher'/>
<def f='linux/crypto/api.c' l='525' ll='557' type='void * crypto_alloc_tfm(const char * alg_name, const struct crypto_type * frontend, u32 type, u32 mask)'/>
<dec f='linux/crypto/api.c' l='558' type='void * crypto_alloc_tfm(const char * , const struct crypto_type * , u32 , u32 )'/>
<use f='linux/crypto/api.c' l='558' c='crypto_alloc_tfm'/>
<use f='linux/crypto/api.c' l='558' u='a'/>
<use f='linux/crypto/api.c' l='558' u='a'/>
<doc f='linux/crypto/api.c' l='505'>/*
 *	crypto_alloc_tfm - Locate algorithm and allocate transform
 *	@alg_name: Name of algorithm
 *	@frontend: Frontend algorithm type
 *	@type: Type of algorithm
 *	@mask: Mask for type comparison
 *
 *	crypto_alloc_tfm() will first attempt to locate an already loaded
 *	algorithm.  If that fails and the kernel supports dynamically loadable
 *	modules, it will then attempt to load a module of the same name or
 *	alias.  If that fails it will send a query to any loaded crypto manager
 *	to construct an algorithm on the fly.  A refcount is grabbed on the
 *	algorithm which is then associated with the new transform.
 *
 *	The returned transform is of a non-determinate type.  Most people
 *	should use one of the more specific allocation functions such as
 *	crypto_alloc_blkcipher.
 *
 *	In case of error the return value is an error pointer.
 */</doc>
<use f='linux/crypto/kpp.c' l='95' u='c' c='crypto_alloc_kpp'/>
<use f='linux/crypto/rng.c' l='118' u='c' c='crypto_alloc_rng'/>
<use f='linux/crypto/shash.c' l='453' u='c' c='crypto_alloc_shash'/>
<use f='linux/crypto/skcipher.c' l='927' u='c' c='crypto_alloc_skcipher'/>
