<dec f='linux/include/linux/skbuff.h' l='3281' type='int skb_shift(struct sk_buff * tgt, struct sk_buff * skb, int shiftlen)'/>
<def f='linux/net/core/skbuff.c' l='3074' ll='3192' type='int skb_shift(struct sk_buff * tgt, struct sk_buff * skb, int shiftlen)'/>
<doc f='linux/net/core/skbuff.c' l='3056'>/**
 * skb_shift - Shifts paged data partially from skb to another
 * @tgt: buffer into which tail data gets added
 * @skb: buffer from which the paged data comes from
 * @shiftlen: shift up to this many bytes
 *
 * Attempts to shift up to shiftlen worth of bytes, which may be less than
 * the length of the skb, from skb to tgt. Returns number bytes shifted.
 * It&apos;s up to caller to free skb if everything was shifted.
 *
 * If @tgt runs out of frags, the whole operation is aborted.
 *
 * Skb cannot include anything else but paged data while tgt is allowed
 * to have non-paged data as well.
 *
 * TODO: full sized shift could be optimized but that would need
 * specialized skb free&apos;er to handle frags without up-to-date nr_frags.
 */</doc>
<use f='linux/net/ipv4/tcp_input.c' l='1460' u='c' c='tcp_shift_skb_data'/>
<use f='linux/net/ipv4/tcp_input.c' l='1478' u='c' c='tcp_shift_skb_data'/>
<use f='linux/net/ipv4/tcp_output.c' l='2747' u='c' c='tcp_collapse_retrans'/>
