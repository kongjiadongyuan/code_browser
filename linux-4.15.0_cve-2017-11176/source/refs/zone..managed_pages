<dec f='linux/include/linux/mmzone.h' l='435' type='unsigned long'/>
<use f='linux/include/linux/mmzone.h' l='836' u='r' c='managed_zone'/>
<offset>768</offset>
<doc f='linux/include/linux/mmzone.h' l='394'>/*
	 * spanned_pages is the total pages spanned by the zone, including
	 * holes, which is calculated as:
	 * 	spanned_pages = zone_end_pfn - zone_start_pfn;
	 *
	 * present_pages is physical pages existing within the zone, which
	 * is calculated as:
	 *	present_pages = spanned_pages - absent_pages(pages in holes);
	 *
	 * managed_pages is present pages managed by the buddy system, which
	 * is calculated as (reserved_pages includes pages allocated by the
	 * bootmem allocator):
	 *	managed_pages = present_pages - reserved_pages;
	 *
	 * So present_pages may be used by memory hotplug or memory power
	 * management logic to figure out unmanaged pages by checking
	 * (present_pages - managed_pages). And managed_pages should be used
	 * by page allocator and vm scanner to calculate all kinds of watermarks
	 * and thresholds.
	 *
	 * Locking rules:
	 *
	 * zone_start_pfn and spanned_pages are protected by span_seqlock.
	 * It is a seqlock because it has to be read outside of zone-&gt;lock,
	 * and it is done in the main allocator path.  But, it is written
	 * quite infrequently.
	 *
	 * The span_seq lock is declared along with zone-&gt;lock because it is
	 * frequently read in proximity to zone-&gt;lock.  It&apos;s good to
	 * give them a chance of being in the same cacheline.
	 *
	 * Write access to present_pages at runtime should be protected by
	 * mem_hotplug_begin/end(). Any reader who can&apos;t tolerant drift of
	 * present_pages should get_online_mems() to get a stable value.
	 *
	 * Read access to managed_pages should be safe because it&apos;s unsigned
	 * long. Write access to zone-&gt;managed_pages and totalram_pages are
	 * protected by managed_page_count_lock at runtime. Idealy only
	 * adjust_managed_page_count() should be used instead of directly
	 * touching zone-&gt;managed_pages and totalram_pages.
	 */</doc>
<use f='linux/lib/show_mem.c' l='31' u='r' c='show_mem'/>
<use f='linux/mm/nobootmem.c' l='160' u='w' c='reset_node_managed_pages'/>
<use f='linux/mm/page_alloc.c' l='1289' u='w' c='__free_pages_boot_core'/>
<use f='linux/mm/page_alloc.c' l='2141' u='r' c='reserve_highatomic_pageblock'/>
<use f='linux/mm/page_alloc.c' l='4531' u='r' c='nr_free_zone_pages'/>
<use f='linux/mm/page_alloc.c' l='4636' u='r' c='si_meminfo_node'/>
<use f='linux/mm/page_alloc.c' l='4852' u='r' c='show_free_areas'/>
<use f='linux/mm/page_alloc.c' l='5444' u='r' c='zone_batchsize'/>
<use f='linux/mm/page_alloc.c' l='5554' u='r' c='pageset_set_high_and_batch'/>
<use f='linux/mm/page_alloc.c' l='6151' u='w' c='free_area_init_core'/>
<use f='linux/mm/page_alloc.c' l='6765' u='w' c='adjust_managed_page_count'/>
<use f='linux/mm/page_alloc.c' l='6944' u='r' c='calculate_totalreserve_pages'/>
<use f='linux/mm/page_alloc.c' l='6945' u='r' c='calculate_totalreserve_pages'/>
<use f='linux/mm/page_alloc.c' l='6969' u='r' c='setup_per_zone_lowmem_reserve'/>
<use f='linux/mm/page_alloc.c' l='6985' u='r' c='setup_per_zone_lowmem_reserve'/>
<use f='linux/mm/page_alloc.c' l='7004' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7011' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7025' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7042' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7042' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7042' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7042' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux/mm/page_alloc.c' l='7172' u='r' c='setup_min_unmapped_ratio'/>
<use f='linux/mm/page_alloc.c' l='7200' u='r' c='setup_min_slab_ratio'/>
<use f='linux/mm/vmstat.c' l='230' u='r' c='calculate_normal_threshold'/>
<use f='linux/mm/vmstat.c' l='1591' u='r' c='zoneinfo_show_print'/>
